{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94356631",
   "metadata": {},
   "source": [
    "# Adding Sentiment Scores to Reddit Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff67acb8",
   "metadata": {},
   "source": [
    "## Part 0: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8b3f16",
   "metadata": {},
   "source": [
    "#### Setup basic utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5560a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import pyarrow\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Check if running in Google Colab\n",
    "def is_colab():\n",
    "    from IPython import get_ipython\n",
    "    return get_ipython().__class__.__module__ == \"google.colab._shell\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ac5ed6",
   "metadata": {},
   "source": [
    "#### Setup NLTK (Natural Language Tool Kit) utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fe1fd9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to ./NLTK_DATA...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to ./NLTK_DATA...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to ./NLTK_DATA...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to ./NLTK_DATA...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package names to ./NLTK_DATA...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     ./NLTK_DATA...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to ./NLTK_DATA...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os, re\n",
    "\n",
    "# Set the NLTK data directory\n",
    "NLTK_DOWNLOAD_DIR = './NLTK_DATA'\n",
    "os.environ[\"NLTK_DATA\"]=NLTK_DOWNLOAD_DIR\n",
    "\n",
    "# Then, import NLTK and download the necessary data.\n",
    "import nltk\n",
    "\n",
    "# Do not download this data without understanding the implications.\n",
    "nltk.download(['punkt',\n",
    "               'punkt_tab',\n",
    "               'stopwords',\n",
    "               'vader_lexicon',\n",
    "               'names',\n",
    "               'averaged_perceptron_tagger',\n",
    "               'wordnet'], download_dir=NLTK_DOWNLOAD_DIR)\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd730c0c",
   "metadata": {},
   "source": [
    "## Part 1: Read Collected Reddit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9e6d2a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission collection shape: (798, 13)\n"
     ]
    }
   ],
   "source": [
    "# Save the collected data to parquet format\n",
    "SUBMISSION_PARQUET_PATH = './data/wallstreetbets-collection.parquet'\n",
    "\n",
    "# Create a pyarrow schema for the data types.\n",
    "submission_schema = pyarrow.schema([\n",
    "    ('title', pyarrow.string()),\n",
    "    ('created_utc', pyarrow.float64()),\n",
    "    ('id', pyarrow.string()),\n",
    "    ('is_original_content', pyarrow.bool_()),\n",
    "    ('link_flair_text', pyarrow.string()),\n",
    "    ('locked', pyarrow.bool_()),\n",
    "    ('name', pyarrow.string()),\n",
    "    ('num_comments', pyarrow.int64()),\n",
    "    ('over_18', pyarrow.bool_()),\n",
    "    ('permalink', pyarrow.string()),\n",
    "    ('selftext', pyarrow.string()),\n",
    "    ('spoiler', pyarrow.bool_()),\n",
    "    ('upvote_ratio', pyarrow.float64()),\n",
    "])\n",
    "\n",
    "submission_collection = pd.read_parquet(SUBMISSION_PARQUET_PATH, engine='pyarrow', schema=submission_schema)\n",
    "# Print some details about the submission collection.\n",
    "print(f\"Submission collection shape: {submission_collection.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "44ee7652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>locked</th>\n",
       "      <th>name</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>over_18</th>\n",
       "      <th>permalink</th>\n",
       "      <th>selftext</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>upvote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nivea Along</td>\n",
       "      <td>1.744832e+09</td>\n",
       "      <td>1k0t4jk</td>\n",
       "      <td>False</td>\n",
       "      <td>YOLO</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1k0t4jk</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/1k0t4jk/nivea_along/</td>\n",
       "      <td>After -7% yesterday and -10% today</td>\n",
       "      <td>False</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Powell to Volatile Stock Market: You’re on You...</td>\n",
       "      <td>1.744836e+09</td>\n",
       "      <td>1k0unbq</td>\n",
       "      <td>False</td>\n",
       "      <td>News</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1k0unbq</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/1k0unbq/powell_to_v...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Super sick timing</td>\n",
       "      <td>1.744835e+09</td>\n",
       "      <td>1k0umm6</td>\n",
       "      <td>False</td>\n",
       "      <td>Loss</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1k0umm6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/1k0umm6/super_sick_...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My second week trading options. SPY BAC and BABA</td>\n",
       "      <td>1.744835e+09</td>\n",
       "      <td>1k0ugf8</td>\n",
       "      <td>False</td>\n",
       "      <td>Gain</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1k0ugf8</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/1k0ugf8/my_second_w...</td>\n",
       "      <td>This is my second—and hopefully last—week trad...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don’t see this too often</td>\n",
       "      <td>1.744835e+09</td>\n",
       "      <td>1k0ubo1</td>\n",
       "      <td>False</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1k0ubo1</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/1k0ubo1/dont_see_th...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   created_utc       id  \\\n",
       "0                                        Nivea Along  1.744832e+09  1k0t4jk   \n",
       "1  Powell to Volatile Stock Market: You’re on You...  1.744836e+09  1k0unbq   \n",
       "2                                  Super sick timing  1.744835e+09  1k0umm6   \n",
       "3   My second week trading options. SPY BAC and BABA  1.744835e+09  1k0ugf8   \n",
       "4                           Don’t see this too often  1.744835e+09  1k0ubo1   \n",
       "\n",
       "   is_original_content link_flair_text  locked        name  num_comments  \\\n",
       "0                False            YOLO   False  t3_1k0t4jk             5   \n",
       "1                False            News   False  t3_1k0unbq             2   \n",
       "2                False            Loss   False  t3_1k0umm6             3   \n",
       "3                False            Gain   False  t3_1k0ugf8             1   \n",
       "4                False      Discussion   False  t3_1k0ubo1            11   \n",
       "\n",
       "   over_18                                          permalink  \\\n",
       "0    False    /r/wallstreetbets/comments/1k0t4jk/nivea_along/   \n",
       "1    False  /r/wallstreetbets/comments/1k0unbq/powell_to_v...   \n",
       "2    False  /r/wallstreetbets/comments/1k0umm6/super_sick_...   \n",
       "3    False  /r/wallstreetbets/comments/1k0ugf8/my_second_w...   \n",
       "4    False  /r/wallstreetbets/comments/1k0ubo1/dont_see_th...   \n",
       "\n",
       "                                            selftext  spoiler  upvote_ratio  \n",
       "0                After -7% yesterday and -10% today     False          0.67  \n",
       "1                                                       False          0.86  \n",
       "2                                                       False          0.75  \n",
       "3  This is my second—and hopefully last—week trad...    False          0.75  \n",
       "4                                                       False          0.86  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first few rows of the submission collection.\n",
    "display(submission_collection.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6a64cea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment collection shape: (151805, 7)\n"
     ]
    }
   ],
   "source": [
    "# Save the collected data to parquet format\n",
    "COMMENT_PARQUET_PATH = './data/wallstreetbets-comment-collection.parquet'\n",
    "\n",
    "# Create a pyarrow schema for the comment data\n",
    "comment_schema = pyarrow.schema([\n",
    "    ('parent_post_id', pyarrow.string()),\n",
    "    ('parent_comment_id', pyarrow.string()),\n",
    "    ('comment_id', pyarrow.string()),\n",
    "    ('author', pyarrow.string()),\n",
    "    ('created_utc', pyarrow.float64()),\n",
    "    ('score', pyarrow.int64()),\n",
    "    ('body', pyarrow.string())\n",
    "])\n",
    "\n",
    "comment_collection = pd.read_parquet(COMMENT_PARQUET_PATH, engine='pyarrow', schema=comment_schema)\n",
    "print(f\"Comment collection shape: {comment_collection.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bd799451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_post_id</th>\n",
       "      <th>parent_comment_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1jwqbs7</td>\n",
       "      <td>t1_mmq5ys9</td>\n",
       "      <td>mmr2q1q</td>\n",
       "      <td>JazzlikePackage5128</td>\n",
       "      <td>1.744474e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>Ty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1jwqbs7</td>\n",
       "      <td>t1_mmumxfs</td>\n",
       "      <td>mn0wa66</td>\n",
       "      <td>shmoopdoop6969</td>\n",
       "      <td>1.744615e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>why</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1jwqbs7</td>\n",
       "      <td>t1_mn0gfl4</td>\n",
       "      <td>mnavkz2</td>\n",
       "      <td>diggin-the-doge</td>\n",
       "      <td>1.744752e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>I take it all back. Tim Dillon special just re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1jwqbs7</td>\n",
       "      <td>t1_mmxdo0h</td>\n",
       "      <td>mmzwh9l</td>\n",
       "      <td>Hugheston987</td>\n",
       "      <td>1.744597e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>![img](emote|t5_2th52|58355)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1jwqbs7</td>\n",
       "      <td>t1_mmplbah</td>\n",
       "      <td>mmsxb6r</td>\n",
       "      <td>markHart99</td>\n",
       "      <td>1.744496e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>![img](emote|t5_2th52|4258)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_post_id parent_comment_id comment_id               author  \\\n",
       "0        1jwqbs7        t1_mmq5ys9    mmr2q1q  JazzlikePackage5128   \n",
       "1        1jwqbs7        t1_mmumxfs    mn0wa66       shmoopdoop6969   \n",
       "2        1jwqbs7        t1_mn0gfl4    mnavkz2      diggin-the-doge   \n",
       "3        1jwqbs7        t1_mmxdo0h    mmzwh9l         Hugheston987   \n",
       "4        1jwqbs7        t1_mmplbah    mmsxb6r           markHart99   \n",
       "\n",
       "    created_utc  score                                               body  \n",
       "0  1.744474e+09      1                                                 Ty  \n",
       "1  1.744615e+09      1                                                why  \n",
       "2  1.744752e+09      1  I take it all back. Tim Dillon special just re...  \n",
       "3  1.744597e+09      1                       ![img](emote|t5_2th52|58355)  \n",
       "4  1.744496e+09      1                        ![img](emote|t5_2th52|4258)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first few rows of the comment collection.\n",
    "display(comment_collection.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b75618",
   "metadata": {},
   "source": [
    "## Part 2: Initial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8ac17c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Sentiment Intensity Analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to analyze sentiment of a single comment\n",
    "def analyze_sentiment(comment):\n",
    "    # Tokenize the comment\n",
    "    tokens = word_tokenize(comment.lower())\n",
    "\n",
    "    # Remove stop words\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Get sentiment scores\n",
    "    sentiment_scores = sia.polarity_scores(' '.join(filtered_tokens))\n",
    "\n",
    "    return sentiment_scores\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "68508d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission Details:\n",
      "Dumping submission details: {'title': 'Nivea Along', 'created_utc': 1744831733.0, 'id': '1k0t4jk', 'is_original_content': False, 'link_flair_text': 'YOLO', 'locked': False, 'name': 't3_1k0t4jk', 'num_comments': 5, 'over_18': False, 'permalink': '/r/wallstreetbets/comments/1k0t4jk/nivea_along/', 'selftext': 'After -7% yesterday and -10% today ', 'spoiler': False, 'upvote_ratio': 0.67}\n",
      "--------------------------------------------------------------------------------\n",
      "Submission: Nivea Along\n",
      "Sentiment Scores: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Get the first submssion from the collection\n",
    "submission = submission_collection.iloc[0]\n",
    "print(f\"Submission Details:\")\n",
    "print(f\"Dumping submission details: {submission.to_dict()}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Show the results of the analysis.\n",
    "sentiment_scores = analyze_sentiment(submission.title)\n",
    "print(f\"Submission: {submission.title}\")\n",
    "print(f\"Sentiment Scores: {sentiment_scores}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be2438a",
   "metadata": {},
   "source": [
    "## Part 3: Sentiment Score for Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "28731bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding sentiment scores to the submission collection...\n",
      "Provided the analysis for fields: selftext.\n",
      "--------------------------------------------------------------------------------\n",
      "Sentiment scores added to the submission collection.\n",
      "--------------------------------------------------------------------------------\n",
      "Example of the submission collection with sentiment scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nivea Along</td>\n",
       "      <td>After -7% yesterday and -10% today</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Powell to Volatile Stock Market: You’re on You...</td>\n",
       "      <td></td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Super sick timing</td>\n",
       "      <td></td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My second week trading options. SPY BAC and BABA</td>\n",
       "      <td>This is my second—and hopefully last—week trad...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.671, 'pos': 0.329, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don’t see this too often</td>\n",
       "      <td></td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I was about to rope and then +97k</td>\n",
       "      <td></td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Powell says Federal Reserve can wait on any in...</td>\n",
       "      <td></td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Made back the last Wendy’s paycheck I lost</td>\n",
       "      <td></td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What Are Your Moves Tomorrow, April 17, 2025</td>\n",
       "      <td>This post contains content not supported on ol...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.827, 'pos': 0.173, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>After market observation. When I finished buyi...</td>\n",
       "      <td>https://preview.redd.it/41ilvj6f39ve1.png?widt...</td>\n",
       "      <td>{'neg': 0.034, 'neu': 0.882, 'pos': 0.085, 'co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                        Nivea Along   \n",
       "1  Powell to Volatile Stock Market: You’re on You...   \n",
       "2                                  Super sick timing   \n",
       "3   My second week trading options. SPY BAC and BABA   \n",
       "4                           Don’t see this too often   \n",
       "5                  I was about to rope and then +97k   \n",
       "6  Powell says Federal Reserve can wait on any in...   \n",
       "7         Made back the last Wendy’s paycheck I lost   \n",
       "8       What Are Your Moves Tomorrow, April 17, 2025   \n",
       "9  After market observation. When I finished buyi...   \n",
       "\n",
       "                                            selftext  \\\n",
       "0                After -7% yesterday and -10% today    \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  This is my second—and hopefully last—week trad...   \n",
       "4                                                      \n",
       "5                                                      \n",
       "6                                                      \n",
       "7                                                      \n",
       "8  This post contains content not supported on ol...   \n",
       "9  https://preview.redd.it/41ilvj6f39ve1.png?widt...   \n",
       "\n",
       "                                           sentiment  \n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "1  {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...  \n",
       "2  {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...  \n",
       "3  {'neg': 0.0, 'neu': 0.671, 'pos': 0.329, 'comp...  \n",
       "4  {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...  \n",
       "5  {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...  \n",
       "6  {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...  \n",
       "7  {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...  \n",
       "8  {'neg': 0.0, 'neu': 0.827, 'pos': 0.173, 'comp...  \n",
       "9  {'neg': 0.034, 'neu': 0.882, 'pos': 0.085, 'co...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Parse the sentiment scores into separate columns.\n",
      "Add four columns to the submission collection.\n",
      "Sentiment scores parsed into separate columns.\n",
      "--------------------------------------------------------------------------------\n",
      "Add a predicted (ss_) to the sentiment scores columns.\n",
      "Sentiment scores columns renamed.\n",
      "--------------------------------------------------------------------------------\n",
      "Example of the submission collection with sentiment scores parsed into separate columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>ss_neg</th>\n",
       "      <th>ss_neu</th>\n",
       "      <th>ss_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nivea Along</td>\n",
       "      <td>After -7% yesterday and -10% today</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Powell to Volatile Stock Market: You’re on You...</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Super sick timing</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My second week trading options. SPY BAC and BABA</td>\n",
       "      <td>This is my second—and hopefully last—week trad...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don’t see this too often</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I was about to rope and then +97k</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Powell says Federal Reserve can wait on any in...</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Made back the last Wendy’s paycheck I lost</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What Are Your Moves Tomorrow, April 17, 2025</td>\n",
       "      <td>This post contains content not supported on ol...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>After market observation. When I finished buyi...</td>\n",
       "      <td>https://preview.redd.it/41ilvj6f39ve1.png?widt...</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                        Nivea Along   \n",
       "1  Powell to Volatile Stock Market: You’re on You...   \n",
       "2                                  Super sick timing   \n",
       "3   My second week trading options. SPY BAC and BABA   \n",
       "4                           Don’t see this too often   \n",
       "5                  I was about to rope and then +97k   \n",
       "6  Powell says Federal Reserve can wait on any in...   \n",
       "7         Made back the last Wendy’s paycheck I lost   \n",
       "8       What Are Your Moves Tomorrow, April 17, 2025   \n",
       "9  After market observation. When I finished buyi...   \n",
       "\n",
       "                                            selftext  ss_neg  ss_neu  ss_pos  \n",
       "0                After -7% yesterday and -10% today    0.000   1.000   0.000  \n",
       "1                                                      0.000   0.000   0.000  \n",
       "2                                                      0.000   0.000   0.000  \n",
       "3  This is my second—and hopefully last—week trad...   0.000   0.671   0.329  \n",
       "4                                                      0.000   0.000   0.000  \n",
       "5                                                      0.000   0.000   0.000  \n",
       "6                                                      0.000   0.000   0.000  \n",
       "7                                                      0.000   0.000   0.000  \n",
       "8  This post contains content not supported on ol...   0.000   0.827   0.173  \n",
       "9  https://preview.redd.it/41ilvj6f39ve1.png?widt...   0.034   0.882   0.085  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add the sentiment scores to the submission collection.\n",
    "print(\"Adding sentiment scores to the submission collection...\")\n",
    "print(\"Provided the analysis for fields: selftext.\")\n",
    "print(\"-\" * 80)\n",
    "submission_collection['sentiment'] = submission_collection['selftext'].apply(analyze_sentiment)\n",
    "print(\"Sentiment scores added to the submission collection.\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Example of the submission collection with sentiment scores:\")\n",
    "display(submission_collection[['title', 'selftext', 'sentiment']].head(10))\n",
    "print(\"-\" * 80)\n",
    "print(\"Parse the sentiment scores into separate columns.\")\n",
    "print(\"Add four columns to the submission collection.\")\n",
    "submission_collection[['neg', 'neu', 'pos', 'compound']] = submission_collection['sentiment'].apply(pd.Series)\n",
    "print(\"Sentiment scores parsed into separate columns.\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Add a predicted (ss_) to the sentiment scores columns.\")\n",
    "submission_collection.rename(columns={'neg': 'ss_neg', 'neu': 'ss_neu', 'pos': 'ss_pos', 'compound': 'ss_compound'}, inplace=True)\n",
    "print(\"Sentiment scores columns renamed.\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Example of the submission collection with sentiment scores parsed into separate columns:\")\n",
    "display(submission_collection[['title', 'selftext', 'ss_neg', 'ss_neu', 'ss_pos']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "46e0b573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding sentiment scores to the comment collection...\n",
      "Provided the analysis for fields: body.\n",
      "--------------------------------------------------------------------------------\n",
      "Sentiment scores added to the comment collection.\n",
      "--------------------------------------------------------------------------------\n",
      "Example of the comment collection with sentiment scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ty</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I take it all back. Tim Dillon special just re...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.69, 'pos': 0.31, 'compou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>![img](emote|t5_2th52|58355)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>![img](emote|t5_2th52|4258)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yes</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Little retards are legitimately in shock ![img...</td>\n",
       "      <td>{'neg': 0.345, 'neu': 0.655, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Feels like a horrible time to look for a diffe...</td>\n",
       "      <td>{'neg': 0.424, 'neu': 0.424, 'pos': 0.152, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AMD and NVDA are down 10% ![img](emote|t5_2th5...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This is a classic Powell talks and shit hits t...</td>\n",
       "      <td>{'neg': 0.211, 'neu': 0.409, 'pos': 0.38, 'com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  \\\n",
       "0                                                 Ty   \n",
       "1                                                why   \n",
       "2  I take it all back. Tim Dillon special just re...   \n",
       "3                       ![img](emote|t5_2th52|58355)   \n",
       "4                        ![img](emote|t5_2th52|4258)   \n",
       "5                                                yes   \n",
       "6  Little retards are legitimately in shock ![img...   \n",
       "7  Feels like a horrible time to look for a diffe...   \n",
       "8  AMD and NVDA are down 10% ![img](emote|t5_2th5...   \n",
       "9  This is a classic Powell talks and shit hits t...   \n",
       "\n",
       "                                           sentiment  \n",
       "0  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...  \n",
       "1  {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...  \n",
       "2  {'neg': 0.0, 'neu': 0.69, 'pos': 0.31, 'compou...  \n",
       "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "5  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...  \n",
       "6  {'neg': 0.345, 'neu': 0.655, 'pos': 0.0, 'comp...  \n",
       "7  {'neg': 0.424, 'neu': 0.424, 'pos': 0.152, 'co...  \n",
       "8  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "9  {'neg': 0.211, 'neu': 0.409, 'pos': 0.38, 'com...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Parse the sentiment scores into separate columns.\n",
      "Add four columns to the comment collection.\n",
      "Sentiment scores parsed into separate columns.\n",
      "--------------------------------------------------------------------------------\n",
      "Add a predicted (ss_) to the sentiment scores columns.\n",
      "Sentiment scores columns renamed.\n",
      "--------------------------------------------------------------------------------\n",
      "Example of the submission collection with sentiment scores parsed into separate columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>ss_neg</th>\n",
       "      <th>ss_neu</th>\n",
       "      <th>ss_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ty</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I take it all back. Tim Dillon special just re...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>![img](emote|t5_2th52|58355)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>![img](emote|t5_2th52|4258)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yes</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Little retards are legitimately in shock ![img...</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Feels like a horrible time to look for a diffe...</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AMD and NVDA are down 10% ![img](emote|t5_2th5...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This is a classic Powell talks and shit hits t...</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  ss_neg  ss_neu  ss_pos\n",
       "0                                                 Ty   0.000   0.000   1.000\n",
       "1                                                why   0.000   0.000   0.000\n",
       "2  I take it all back. Tim Dillon special just re...   0.000   0.690   0.310\n",
       "3                       ![img](emote|t5_2th52|58355)   0.000   1.000   0.000\n",
       "4                        ![img](emote|t5_2th52|4258)   0.000   1.000   0.000\n",
       "5                                                yes   0.000   0.000   1.000\n",
       "6  Little retards are legitimately in shock ![img...   0.345   0.655   0.000\n",
       "7  Feels like a horrible time to look for a diffe...   0.424   0.424   0.152\n",
       "8  AMD and NVDA are down 10% ![img](emote|t5_2th5...   0.000   1.000   0.000\n",
       "9  This is a classic Powell talks and shit hits t...   0.211   0.409   0.380"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add the sentiment scores to the submission collection.\n",
    "print(\"Adding sentiment scores to the comment collection...\")\n",
    "print(\"Provided the analysis for fields: body.\")\n",
    "print(\"-\" * 80)\n",
    "comment_collection['sentiment'] = comment_collection['body'].apply(analyze_sentiment)\n",
    "print(\"Sentiment scores added to the comment collection.\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Example of the comment collection with sentiment scores:\")\n",
    "display(comment_collection[['body', 'sentiment']].head(10))\n",
    "print(\"-\" * 80)\n",
    "print(\"Parse the sentiment scores into separate columns.\")\n",
    "print(\"Add four columns to the comment collection.\")\n",
    "comment_collection[['neg', 'neu', 'pos', 'compound']] = comment_collection['sentiment'].apply(pd.Series)\n",
    "print(\"Sentiment scores parsed into separate columns.\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Add a predicted (ss_) to the sentiment scores columns.\")\n",
    "comment_collection.rename(columns={'neg': 'ss_neg', 'neu': 'ss_neu', 'pos': 'ss_pos', 'compound': 'ss_compound'}, inplace=True)\n",
    "print(\"Sentiment scores columns renamed.\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Example of the submission collection with sentiment scores parsed into separate columns:\")\n",
    "display(comment_collection[['body', 'ss_neg', 'ss_neu', 'ss_pos']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a7353a",
   "metadata": {},
   "source": [
    "## Part 4: Update Reddit Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5ba6a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the collected data to parquet format\n",
    "COMMENT_PARQUET_PATH = './data/wallstreetbets-comment-collection-wss.parquet'\n",
    "\n",
    "# Create a pyarrow schema for the comment data\n",
    "comment_schema = pyarrow.schema([\n",
    "    ('parent_post_id', pyarrow.string()),\n",
    "    ('parent_comment_id', pyarrow.string()),\n",
    "    ('comment_id', pyarrow.string()),\n",
    "    ('author', pyarrow.string()),\n",
    "    ('created_utc', pyarrow.float64()),\n",
    "    ('score', pyarrow.int64()),\n",
    "    ('body', pyarrow.string()),\n",
    "    ('ss_neg', pyarrow.float64()),\n",
    "    ('ss_neu', pyarrow.float64()),\n",
    "    ('ss_pos', pyarrow.float64()),\n",
    "    ('ss_compound', pyarrow.float64())\n",
    "])\n",
    "\n",
    "# Save the collected data to parquet format\n",
    "comment_collection.to_parquet(COMMENT_PARQUET_PATH, engine='pyarrow', schema=comment_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "519aa318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the collected data to parquet format\n",
    "SUBMISSION_PARQUET_PATH = './data/wallstreetbets-collection-wss.parquet'\n",
    "\n",
    "# Create a pyarrow schema for the data types.\n",
    "submission_schema = pyarrow.schema([\n",
    "    ('title', pyarrow.string()),\n",
    "    ('created_utc', pyarrow.float64()),\n",
    "    ('id', pyarrow.string()),\n",
    "    ('is_original_content', pyarrow.bool_()),\n",
    "    ('link_flair_text', pyarrow.string()),\n",
    "    ('locked', pyarrow.bool_()),\n",
    "    ('name', pyarrow.string()),\n",
    "    ('num_comments', pyarrow.int64()),\n",
    "    ('over_18', pyarrow.bool_()),\n",
    "    ('permalink', pyarrow.string()),\n",
    "    ('selftext', pyarrow.string()),\n",
    "    ('spoiler', pyarrow.bool_()),\n",
    "    ('upvote_ratio', pyarrow.float64()),\n",
    "    ('ss_neg', pyarrow.float64()),\n",
    "    ('ss_neu', pyarrow.float64()),\n",
    "    ('ss_pos', pyarrow.float64()),\n",
    "    ('ss_compound', pyarrow.float64())\n",
    "])\n",
    "\n",
    "# Save the collected data to parquet format\n",
    "submission_collection.to_parquet(SUBMISSION_PARQUET_PATH, engine='pyarrow', schema=submission_schema)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
