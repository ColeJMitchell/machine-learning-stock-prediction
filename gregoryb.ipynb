{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import praw, time, json\n",
    "from IPython.display import display\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "from requests import Session\n",
    "import pandas as pd\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('.env')\n",
    "config = dotenv_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Reddit Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to Reddit!\n",
      "Logged in as: u/GregorybLafayetteML\n"
     ]
    }
   ],
   "source": [
    "# Create a custom session with a timeout\n",
    "session = Session()\n",
    "session.headers.update({'User-Agent': 'praw'})\n",
    "session.timeout = 10  # Set a timeout of 10 seconds\n",
    "\n",
    "# Login to Reddit using PRAW\n",
    "reddit = praw.Reddit(\n",
    "    client_id=config['CLIENT_ID'],\n",
    "    client_secret=config['CLIENT_SECRET'],\n",
    "    requestor_kwargs={\"session\": session},\n",
    "    username=config['USERNAME'],\n",
    "    password=config['PASSWORD'],\n",
    "    user_agent=\"CS470 ML Project Access by u/GregorybLafayetteML\"\n",
    ")\n",
    "\n",
    "# Add some peripheral config data\n",
    "reddit.config.log_requests = 1\n",
    "reddit.config.store_json_result = True\n",
    "\n",
    "# Test the connection\n",
    "try:\n",
    "    username = reddit.user.me()\n",
    "    print(\"Successfully logged in to Reddit!\")\n",
    "    print(f\"Logged in as: u/{username}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to log in: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Accessing Reddit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access reddit posts, we'll need send a request with the number of post we want to get. The following example finds the top 10 hottest posts on the u/wallstreetbets subreddit. We'll show the post title, score, flair, and URL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 hot posts from r/wallstreetbets:\n",
      "Title: Weekly Earnings Thread 3/31 - 4/4, Score: 96, Flair: Earnings Thread, URL: https://i.redd.it/tjvgxuyo0gre1.jpeg\n",
      "Title: Daily Discussion Thread for April 02, 2025, Score: 227, Flair: Daily Discussion, URL: https://www.reddit.com/r/wallstreetbets/comments/1jpkv70/daily_discussion_thread_for_april_02_2025/\n",
      "Title: Tesla first quarter deliveries: 336,681 delivered, 362,615 produced, Score: 4479, Flair: News, URL: https://ir.tesla.com/press-release/tesla-first-quarter-2025-production-deliveries-and-deployments\n",
      "Title: Tesla shares rise on unconfirmed report Elon Musk could be leaving DOGE post soon, Score: 1807, Flair: News, URL: https://www.cnbc.com/2025/04/02/tesla-shares-rise-on-unconfirmed-report-elon-musk-could-be-leaving-doge-post-soon.html\n",
      "Title: Another Recession indicator?, Score: 444, Flair: Meme, URL: https://www.reddit.com/r/wallstreetbets/comments/1jprerv/another_recession_indicator/\n",
      "Title: â€˜Twas the Night Before Tariffs, Score: 6033, Flair: Meme, URL: https://www.reddit.com/r/wallstreetbets/comments/1jpbpym/twas_the_night_before_tariffs/\n",
      "Title: $4.5k gain on TSLA puts. And to all the people that doubted me suck my balls., Score: 462, Flair: Gain, URL: https://www.reddit.com/gallery/1jpoq6l\n",
      "Title: Amazon bids to buy TikTok as deadline looms, New York Times reports, Score: 217, Flair: News, URL: https://www.reddit.com/r/wallstreetbets/comments/1jptm06/amazon_bids_to_buy_tiktok_as_deadline_looms_new/\n",
      "Title: 135k overnight gain. $TQQQ 58.5 puts and $QQQ 471 puts., Score: 215, Flair: Gain, URL: https://www.reddit.com/r/wallstreetbets/comments/1jpp00a/135k_overnight_gain_tqqq_585_puts_and_qqq_471_puts/\n",
      "Title: Starting the year strong with -$10,000 in deductionsâ€¦, Score: 117, Flair: Loss, URL: https://i.redd.it/6ryi1o0byfse1.jpeg\n"
     ]
    }
   ],
   "source": [
    "top_posts = reddit.subreddit('wallstreetbets').hot(limit=10)\n",
    "print(\"Top 10 hot posts from r/wallstreetbets:\")\n",
    "for post in top_posts:\n",
    "    print(f\"Title: {post.title}, Score: {post.score}, Flair: {post.link_flair_text}, URL: {post.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we'll need far more than ten posts at a time. The reddit API will limit our access to 100 posts at a time. Fortunately, the api uses a ListingGenerator which allows us to access our metered connection in sequential blocks. The following example shows how we can utilize this behavior, grabbing blocks of 100 posts at a time. In our example, we'll grab blocks of posts until we reach 5000 posts or our access times out. Notice that the procedure ends early with around 750-800 posts collected. The results are sparce, because our connection either timed out or was metered down by reddit. The latter option is more likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more posts to fetch.\n",
      "Fetched 787 posts in total.\n"
     ]
    }
   ],
   "source": [
    "# Access the subreddit\n",
    "subreddit = reddit.subreddit(\"wallstreetbets\")\n",
    "\n",
    "# Initialize variables\n",
    "batch_size = 100  # Number of posts per batch\n",
    "total_posts = 5000  # Total number of posts to fetch\n",
    "all_posts = []  # To store all the retrieved posts\n",
    "after = None  # To keep track of the last post for pagination\n",
    "\n",
    "# Fetch posts in batches\n",
    "while len(all_posts) < total_posts:\n",
    "    # Fetch the next batch of posts\n",
    "    submissions = subreddit.new(limit=batch_size, params={\"after\": after})\n",
    "    \n",
    "    batch_posts = []\n",
    "    for submission in submissions:\n",
    "        batch_posts.append(submission)\n",
    "\n",
    "        # Update the `after` variable with the last submission's fullname\n",
    "        after = submission.fullname\n",
    "\n",
    "    # Add the batch to the main list\n",
    "    all_posts.extend(batch_posts)\n",
    "\n",
    "    # Exit loop if no more posts are available\n",
    "    if not batch_posts:\n",
    "        print(\"No more posts to fetch.\")\n",
    "        break\n",
    "\n",
    "    # Optional delay to avoid rate limits\n",
    "    time.sleep(1)  # Adjust the delay as necessary\n",
    "\n",
    "# Process the data (example: print the total number of posts fetched)\n",
    "print(f\"Fetched {len(all_posts)} posts in total.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have collected a large portion of posts/submssions, we'll parse the results and construct a dataframe with this data. We're going to collect more fields from this data than we might need right now, avoiding data limitations in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>edited</th>\n",
       "      <th>id</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>locked</th>\n",
       "      <th>name</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>over_18</th>\n",
       "      <th>permalink</th>\n",
       "      <th>selftext</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>upvote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OnlyFans founder, crypto foundation submit lat...</td>\n",
       "      <td>1.743618e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1jpvkm3</td>\n",
       "      <td>False</td>\n",
       "      <td>News</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1jpvkm3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/1jpvkm3/onlyfans_fo...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can we get a WSB broadcast?</td>\n",
       "      <td>1.743618e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1jpvjrn</td>\n",
       "      <td>False</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1jpvjrn</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/1jpvjrn/can_we_get_...</td>\n",
       "      <td>Iâ€™m tired of listening to CNBC using big words...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chinese firms place $16 billion in order for n...</td>\n",
       "      <td>1.743617e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1jpv6ez</td>\n",
       "      <td>False</td>\n",
       "      <td>News</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1jpv6ez</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/1jpv6ez/chinese_fir...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon bids to buy TikTok as deadline looms, N...</td>\n",
       "      <td>1.743613e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1jptm06</td>\n",
       "      <td>False</td>\n",
       "      <td>News</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1jptm06</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/1jptm06/amazon_bids...</td>\n",
       "      <td>[https://finance.yahoo.com/news/amazon-bid-buy...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rivian posts sharp fall in quarterly deliverie...</td>\n",
       "      <td>1.743609e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1jps2rr</td>\n",
       "      <td>False</td>\n",
       "      <td>News</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1jps2rr</td>\n",
       "      <td>54</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/1jps2rr/rivian_post...</td>\n",
       "      <td>(Reuters) - Rivian reported a 36% decline in f...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>Wow. Sold Friday held calls at open. Swapped f...</td>\n",
       "      <td>1.741034e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1j2sinn</td>\n",
       "      <td>False</td>\n",
       "      <td>Gain</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1j2sinn</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/1j2sinn/wow_sold_fr...</td>\n",
       "      <td>Checkout the last photo. Iâ€™m finally in the gr...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>167% QQQ PUTS 23.5k PROFITS</td>\n",
       "      <td>1.741033e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1j2s2yo</td>\n",
       "      <td>False</td>\n",
       "      <td>Gain</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1j2s2yo</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/1j2s2yo/167_qqq_put...</td>\n",
       "      <td>DUMP IT ðŸ¥­ðŸ¥­ðŸ¥­ðŸ¥­</td>\n",
       "      <td>False</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>13K 0DTE SPY 585 PUT --&gt; +17K Profit</td>\n",
       "      <td>1.741032e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1j2ry4j</td>\n",
       "      <td>False</td>\n",
       "      <td>Gain</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1j2ry4j</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/1j2ry4j/13k_0dte_sp...</td>\n",
       "      <td>Bear wins again  \\n\\n\\nhttps://preview.redd.it...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>Next up for EU sovereignty: cloud computing</td>\n",
       "      <td>1.741030e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1j2qy9i</td>\n",
       "      <td>False</td>\n",
       "      <td>DD</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1j2qy9i</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/1j2qy9i/next_up_for...</td>\n",
       "      <td>(resubmitted with positions)\\n\\n**TL;DR** If E...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>My flair says it all</td>\n",
       "      <td>1.741029e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1j2qocz</td>\n",
       "      <td>False</td>\n",
       "      <td>Loss</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_1j2qocz</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/wallstreetbets/comments/1j2qocz/my_flair_sa...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>787 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title   created_utc  \\\n",
       "0    OnlyFans founder, crypto foundation submit lat...  1.743618e+09   \n",
       "1                          Can we get a WSB broadcast?  1.743618e+09   \n",
       "2    Chinese firms place $16 billion in order for n...  1.743617e+09   \n",
       "3    Amazon bids to buy TikTok as deadline looms, N...  1.743613e+09   \n",
       "4    Rivian posts sharp fall in quarterly deliverie...  1.743609e+09   \n",
       "..                                                 ...           ...   \n",
       "782  Wow. Sold Friday held calls at open. Swapped f...  1.741034e+09   \n",
       "783                        167% QQQ PUTS 23.5k PROFITS  1.741033e+09   \n",
       "784               13K 0DTE SPY 585 PUT --> +17K Profit  1.741032e+09   \n",
       "785        Next up for EU sovereignty: cloud computing  1.741030e+09   \n",
       "786                               My flair says it all  1.741029e+09   \n",
       "\n",
       "    distinguished edited       id  is_original_content link_flair_text  \\\n",
       "0            None  False  1jpvkm3                False            News   \n",
       "1            None  False  1jpvjrn                False      Discussion   \n",
       "2            None  False  1jpv6ez                False            News   \n",
       "3            None  False  1jptm06                False            News   \n",
       "4            None  False  1jps2rr                False            News   \n",
       "..            ...    ...      ...                  ...             ...   \n",
       "782          None  False  1j2sinn                False            Gain   \n",
       "783          None  False  1j2s2yo                False            Gain   \n",
       "784          None  False  1j2ry4j                False            Gain   \n",
       "785          None  False  1j2qy9i                False              DD   \n",
       "786          None  False  1j2qocz                False            Loss   \n",
       "\n",
       "     locked        name  num_comments  over_18  \\\n",
       "0     False  t3_1jpvkm3             1    False   \n",
       "1     False  t3_1jpvjrn             1    False   \n",
       "2     False  t3_1jpv6ez             5    False   \n",
       "3     False  t3_1jptm06            46    False   \n",
       "4     False  t3_1jps2rr            54    False   \n",
       "..      ...         ...           ...      ...   \n",
       "782   False  t3_1j2sinn            11    False   \n",
       "783   False  t3_1j2s2yo            18    False   \n",
       "784   False  t3_1j2ry4j             3    False   \n",
       "785   False  t3_1j2qy9i            15    False   \n",
       "786   False  t3_1j2qocz             9    False   \n",
       "\n",
       "                                             permalink  \\\n",
       "0    /r/wallstreetbets/comments/1jpvkm3/onlyfans_fo...   \n",
       "1    /r/wallstreetbets/comments/1jpvjrn/can_we_get_...   \n",
       "2    /r/wallstreetbets/comments/1jpv6ez/chinese_fir...   \n",
       "3    /r/wallstreetbets/comments/1jptm06/amazon_bids...   \n",
       "4    /r/wallstreetbets/comments/1jps2rr/rivian_post...   \n",
       "..                                                 ...   \n",
       "782  /r/wallstreetbets/comments/1j2sinn/wow_sold_fr...   \n",
       "783  /r/wallstreetbets/comments/1j2s2yo/167_qqq_put...   \n",
       "784  /r/wallstreetbets/comments/1j2ry4j/13k_0dte_sp...   \n",
       "785  /r/wallstreetbets/comments/1j2qy9i/next_up_for...   \n",
       "786  /r/wallstreetbets/comments/1j2qocz/my_flair_sa...   \n",
       "\n",
       "                                              selftext  spoiler  upvote_ratio  \n",
       "0                                                         False          1.00  \n",
       "1    Iâ€™m tired of listening to CNBC using big words...    False          1.00  \n",
       "2                                                         False          0.97  \n",
       "3    [https://finance.yahoo.com/news/amazon-bid-buy...    False          0.97  \n",
       "4    (Reuters) - Rivian reported a 36% decline in f...    False          0.97  \n",
       "..                                                 ...      ...           ...  \n",
       "782  Checkout the last photo. Iâ€™m finally in the gr...    False          0.84  \n",
       "783                                       DUMP IT ðŸ¥­ðŸ¥­ðŸ¥­ðŸ¥­    False          0.96  \n",
       "784  Bear wins again  \\n\\n\\nhttps://preview.redd.it...    False          0.82  \n",
       "785  (resubmitted with positions)\\n\\n**TL;DR** If E...    False          0.92  \n",
       "786                                                       False          0.88  \n",
       "\n",
       "[787 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse are submission objects that we collected.\n",
    "fields = ('title', \n",
    "          'created_utc', \n",
    "          'distinguished', \n",
    "          'edited', \n",
    "          'id', \n",
    "          'is_original_content', \n",
    "          'link_flair_text', \n",
    "          'locked',\n",
    "          'name',\n",
    "          'num_comments',\n",
    "          'over_18',\n",
    "          'permalink',\n",
    "          'selftext',\n",
    "          'spoiler',\n",
    "          'upvote_ratio')\n",
    "list_of_submissions = []\n",
    "\n",
    "# Parse each submission into a dictionary of the lised fields.\n",
    "for submission in all_posts:\n",
    "    full = vars(submission)\n",
    "    sub_dict = {field:full[field] for field in fields}\n",
    "    list_of_submissions.append(sub_dict)\n",
    "\n",
    "# Create a python dataframe of these submissions.\n",
    "collected_data = pd.DataFrame.from_dict(list_of_submissions, orient='columns')\n",
    "\n",
    "# Display the dataframe.\n",
    "display(collected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Analysis of Reddit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
