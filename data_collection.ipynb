{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Collecting Reddit Data from r/WallStreetBets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mqH72oV8BkP"
      },
      "source": [
        "## Part 1: Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoSNYlmE8BkQ"
      },
      "source": [
        "### Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNHmHw-T8BkQ",
        "outputId": "5682a658-2c7f-4d24-e12c-866f8ade2b85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: praw in ./venv/lib/python3.12/site-packages (7.8.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in ./venv/lib/python3.12/site-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in ./venv/lib/python3.12/site-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in ./venv/lib/python3.12/site-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in ./venv/lib/python3.12/site-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.1.31)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pyarrow in ./venv/lib/python3.12/site-packages (19.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: python-dotenv in ./venv/lib/python3.12/site-packages (1.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install the packages if they don't exist.\n",
        "%pip install praw\n",
        "%pip install pyarrow\n",
        "%pip install python-dotenv\n",
        "\n",
        "# Import Packages\n",
        "import praw, time, os, pyarrow\n",
        "from IPython.display import display\n",
        "from dotenv import load_dotenv, dotenv_values\n",
        "from requests import Session\n",
        "import pandas as pd\n",
        "from IPython import get_ipython\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv('.env')\n",
        "config = dotenv_values()\n",
        "\n",
        "# Get config from colab or other environment.\n",
        "def is_colab():\n",
        "    return get_ipython().__class__.__module__ == \"google.colab._shell\"\n",
        "\n",
        "if is_colab():\n",
        "    from google.colab import userdata\n",
        "    config = {}\n",
        "    config['CLIENT_SECRET'] = userdata.get('CLIENT_SECRET')\n",
        "    config['CLIENT_ID'] = userdata.get('CLIENT_ID')\n",
        "    config['NAME'] = userdata.get('NAME')\n",
        "    config['REDIRECT_URI'] = userdata.get('REDIRECT_URI')\n",
        "    config['USERNAME'] = userdata.get('USERNAME')\n",
        "    config['PASSWORD'] = userdata.get('PASSWORD')\n",
        "\n",
        "else:\n",
        "    load_dotenv('.env')\n",
        "    config = dotenv_values()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ6nQKwq8BkR"
      },
      "source": [
        "## Part 2: Collecting Submissions from Reddit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIqcjmZA8BkR"
      },
      "source": [
        "### Open Reddit Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "mkZtaceY8BkR",
        "outputId": "a1b8a895-f6f3-422f-dac8-b7794d675fe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully logged in to Reddit!\n",
            "Logged in as: u/GregorybLafayetteML\n"
          ]
        }
      ],
      "source": [
        "# Create a custom session with a timeout\n",
        "session = Session()\n",
        "session.headers.update({'User-Agent': 'praw'})\n",
        "session.timeout = 10  # Set a timeout of 10 seconds\n",
        "\n",
        "# Login to Reddit using PRAW\n",
        "reddit = praw.Reddit(\n",
        "    client_id=config['CLIENT_ID'],\n",
        "    client_secret=config['CLIENT_SECRET'],\n",
        "    requestor_kwargs={\"session\": session},\n",
        "    username=config['USERNAME'],\n",
        "    password=config['PASSWORD'],\n",
        "    user_agent=\"CS470 ML Project Access by u/GregorybLafayetteML\"\n",
        ")\n",
        "\n",
        "# Add some peripheral config data\n",
        "reddit.config.log_requests = 1\n",
        "reddit.config.store_json_result = True\n",
        "\n",
        "# Test the connection\n",
        "try:\n",
        "    username = reddit.user.me()\n",
        "    print(\"Successfully logged in to Reddit!\")\n",
        "    print(f\"Logged in as: u/{username}\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to log in: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk6FGRfK8BkS"
      },
      "source": [
        "### Accessing Reddit Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnIgfIks8BkT"
      },
      "source": [
        "To access reddit posts, we'll need send a request with the number of post we want to get. The following example finds the top 10 hottest posts on the u/wallstreetbets subreddit. We'll show the post title, score, flair, and URL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MMebUrT98BkT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 hot posts from r/wallstreetbets:\n",
            "Title: Weekly Earnings Thread 4/14 - 4/18, Score: 208, Flair: Earnings Thread, URL: https://i.redd.it/b51iqmecn7ue1.jpeg\n",
            "Title: What Are Your Moves Tomorrow, April 17, 2025, Score: 65, Flair: Daily Discussion, URL: https://www.reddit.com/r/wallstreetbets/comments/1k0tt5k/what_are_your_moves_tomorrow_april_17_2025/\n",
            "Title: Powell indicates tariffs could pose a challenge for the Fed between controlling inflation and supporting economic growth, Score: 5035, Flair: News, URL: https://www.cnbc.com/2025/04/16/powell-indicates-tariffs-could-pose-a-two-pronged-policy-challenge-for-the-fed-.html\n",
            "Title: Powell’s future…., Score: 1506, Flair: Meme, URL: https://v.redd.it/c0gaopbap8ve1\n",
            "Title: Just doubled down on my bet 😬😬😬, Score: 1933, Flair: YOLO, URL: https://i.redd.it/kirarknsw7ve1.jpeg\n",
            "Title: Retail sales surged in March as Americans rushed to beat Trump’s tariffs, Score: 2221, Flair: News, URL: https://www.reddit.com/r/wallstreetbets/comments/1k0jvyb/retail_sales_surged_in_march_as_americans_rushed/\n",
            "Title: White House: China now faces up to a 245% tariff on imports to the United States as a result of its retaliatory actions., Score: 21016, Flair: News, URL: https://www.reddit.com/r/wallstreetbets/comments/1k0b996/white_house_china_now_faces_up_to_a_245_tariff_on/\n",
            "Title: A reminder that Powell speaks today, get yourselves ready, Score: 4015, Flair: Discussion, URL: https://i.redd.it/ssjmpdi7y5ve1.jpeg\n",
            "Title: Ominous, Score: 533, Flair: Discussion, URL: https://i.redd.it/ovlhyl4939ve1.png\n",
            "Title: There won’t be a trade deal between US and China, Score: 2880, Flair: Discussion, URL: https://www.reddit.com/r/wallstreetbets/comments/1k0e00n/there_wont_be_a_trade_deal_between_us_and_china/\n"
          ]
        }
      ],
      "source": [
        "top_posts = reddit.subreddit('wallstreetbets').hot(limit=10)\n",
        "print(\"Top 10 hot posts from r/wallstreetbets:\")\n",
        "for post in top_posts:\n",
        "    print(f\"Title: {post.title}, Score: {post.score}, Flair: {post.link_flair_text}, URL: {post.url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IxVa5Xi8BkU"
      },
      "source": [
        "For this project, we'll need far more than ten posts at a time. The reddit API will limit our access to 100 posts at a time. Fortunately, the api uses a ListingGenerator which allows us to access our metered connection in sequential blocks. The following example shows how we can utilize this behavior, grabbing blocks of 100 posts at a time. In our example, we'll grab blocks of posts until we reach 5000 posts or our access times out. Notice that the procedure ends early with around 750-800 posts collected. The results are sparce, because our connection either timed out or was metered down by reddit. The latter option is more likely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WG2zyxFP8BkU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No more posts to fetch.\n",
            "Fetched 797 posts in total.\n"
          ]
        }
      ],
      "source": [
        "# Access the subreddit\n",
        "subreddit = reddit.subreddit(\"wallstreetbets\")\n",
        "\n",
        "# Initialize variables\n",
        "batch_size = 50 # Number of posts per batch\n",
        "total_posts = 5000  # Total number of posts to fetch\n",
        "all_posts = []  # To store all the retrieved posts\n",
        "after = None  # To keep track of the last post for pagination\n",
        "\n",
        "# Fetch posts in batches\n",
        "while len(all_posts) < total_posts:\n",
        "    # Fetch the next batch of posts\n",
        "    submissions = subreddit.new(limit=batch_size, params={\"after\": after})\n",
        "\n",
        "    batch_posts = []\n",
        "    for submission in submissions:\n",
        "        batch_posts.append(submission)\n",
        "\n",
        "        # Update the `after` variable with the last submission's fullname\n",
        "        after = submission.fullname\n",
        "\n",
        "    # Add the batch to the main list\n",
        "    all_posts.extend(batch_posts)\n",
        "\n",
        "    # Exit loop if no more posts are available\n",
        "    if not batch_posts:\n",
        "        print(\"No more posts to fetch.\")\n",
        "        break\n",
        "\n",
        "    # Optional delay to avoid rate limits\n",
        "    time.sleep(5)  # Adjust the delay as necessary\n",
        "\n",
        "# Process the data (example: print the total number of posts fetched)\n",
        "print(f\"Fetched {len(all_posts)} posts in total.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_4N4b2q8BkU"
      },
      "source": [
        "Now that we have collected a large portion of posts/submssions, we'll parse the results and construct a dataframe with this data. We're going to collect more fields from this data than we might need right now, avoiding data limitations in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "69crArfG8BkU"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>id</th>\n",
              "      <th>is_original_content</th>\n",
              "      <th>link_flair_text</th>\n",
              "      <th>locked</th>\n",
              "      <th>name</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>over_18</th>\n",
              "      <th>permalink</th>\n",
              "      <th>selftext</th>\n",
              "      <th>spoiler</th>\n",
              "      <th>upvote_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Powell to Volatile Stock Market: You’re on You...</td>\n",
              "      <td>1.744836e+09</td>\n",
              "      <td>1k0unbq</td>\n",
              "      <td>False</td>\n",
              "      <td>News</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0unbq</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0unbq/powell_to_v...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Super sick timing</td>\n",
              "      <td>1.744835e+09</td>\n",
              "      <td>1k0umm6</td>\n",
              "      <td>False</td>\n",
              "      <td>Loss</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0umm6</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0umm6/super_sick_...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>My second week trading options. SPY BAC and BABA</td>\n",
              "      <td>1.744835e+09</td>\n",
              "      <td>1k0ugf8</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0ugf8</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0ugf8/my_second_w...</td>\n",
              "      <td>This is my second—and hopefully last—week trad...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Don’t see this too often</td>\n",
              "      <td>1.744835e+09</td>\n",
              "      <td>1k0ubo1</td>\n",
              "      <td>False</td>\n",
              "      <td>Discussion</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0ubo1</td>\n",
              "      <td>11</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0ubo1/dont_see_th...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I was about to rope and then +97k</td>\n",
              "      <td>1.744834e+09</td>\n",
              "      <td>1k0u286</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0u286</td>\n",
              "      <td>10</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0u286/i_was_about...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>792</th>\n",
              "      <td>Account Blew Up In One Day</td>\n",
              "      <td>1.743226e+09</td>\n",
              "      <td>1jmff4z</td>\n",
              "      <td>False</td>\n",
              "      <td>Loss</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jmff4z</td>\n",
              "      <td>106</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jmff4z/account_ble...</td>\n",
              "      <td>Had a successful 20 day run up with a small $2...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>793</th>\n",
              "      <td>Pretty Good Friday</td>\n",
              "      <td>1.743223e+09</td>\n",
              "      <td>1jmei0h</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jmei0h</td>\n",
              "      <td>23</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jmei0h/pretty_good...</td>\n",
              "      <td>Had a feeling we’d sell off hard for PCE even ...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794</th>\n",
              "      <td>Oracle to build cluster of 30,000 AMD MI355X GPUs</td>\n",
              "      <td>1.743214e+09</td>\n",
              "      <td>1jmbxap</td>\n",
              "      <td>False</td>\n",
              "      <td>News</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jmbxap</td>\n",
              "      <td>50</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jmbxap/oracle_to_b...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>299 to 5k. Baby gains but fuck NVDA</td>\n",
              "      <td>1.743210e+09</td>\n",
              "      <td>1jmamu6</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jmamu6</td>\n",
              "      <td>78</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jmamu6/299_to_5k_b...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>Hard Work and Patience Pays Off</td>\n",
              "      <td>1.743203e+09</td>\n",
              "      <td>1jm85ur</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jm85ur</td>\n",
              "      <td>47</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jm85ur/hard_work_a...</td>\n",
              "      <td>Lot of people on WSB treat the Market like a c...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.66</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>797 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 title   created_utc       id  \\\n",
              "0    Powell to Volatile Stock Market: You’re on You...  1.744836e+09  1k0unbq   \n",
              "1                                    Super sick timing  1.744835e+09  1k0umm6   \n",
              "2     My second week trading options. SPY BAC and BABA  1.744835e+09  1k0ugf8   \n",
              "3                             Don’t see this too often  1.744835e+09  1k0ubo1   \n",
              "4                    I was about to rope and then +97k  1.744834e+09  1k0u286   \n",
              "..                                                 ...           ...      ...   \n",
              "792                         Account Blew Up In One Day  1.743226e+09  1jmff4z   \n",
              "793                                 Pretty Good Friday  1.743223e+09  1jmei0h   \n",
              "794  Oracle to build cluster of 30,000 AMD MI355X GPUs  1.743214e+09  1jmbxap   \n",
              "795                299 to 5k. Baby gains but fuck NVDA  1.743210e+09  1jmamu6   \n",
              "796                    Hard Work and Patience Pays Off  1.743203e+09  1jm85ur   \n",
              "\n",
              "     is_original_content link_flair_text  locked        name  num_comments  \\\n",
              "0                  False            News   False  t3_1k0unbq             2   \n",
              "1                  False            Loss   False  t3_1k0umm6             3   \n",
              "2                  False            Gain   False  t3_1k0ugf8             1   \n",
              "3                  False      Discussion   False  t3_1k0ubo1            11   \n",
              "4                  False            Gain   False  t3_1k0u286            10   \n",
              "..                   ...             ...     ...         ...           ...   \n",
              "792                False            Loss   False  t3_1jmff4z           106   \n",
              "793                False            Gain   False  t3_1jmei0h            23   \n",
              "794                False            News   False  t3_1jmbxap            50   \n",
              "795                False            Gain   False  t3_1jmamu6            78   \n",
              "796                False            Gain   False  t3_1jm85ur            47   \n",
              "\n",
              "     over_18                                          permalink  \\\n",
              "0      False  /r/wallstreetbets/comments/1k0unbq/powell_to_v...   \n",
              "1      False  /r/wallstreetbets/comments/1k0umm6/super_sick_...   \n",
              "2      False  /r/wallstreetbets/comments/1k0ugf8/my_second_w...   \n",
              "3      False  /r/wallstreetbets/comments/1k0ubo1/dont_see_th...   \n",
              "4      False  /r/wallstreetbets/comments/1k0u286/i_was_about...   \n",
              "..       ...                                                ...   \n",
              "792    False  /r/wallstreetbets/comments/1jmff4z/account_ble...   \n",
              "793    False  /r/wallstreetbets/comments/1jmei0h/pretty_good...   \n",
              "794    False  /r/wallstreetbets/comments/1jmbxap/oracle_to_b...   \n",
              "795    False  /r/wallstreetbets/comments/1jmamu6/299_to_5k_b...   \n",
              "796    False  /r/wallstreetbets/comments/1jm85ur/hard_work_a...   \n",
              "\n",
              "                                              selftext  spoiler  upvote_ratio  \n",
              "0                                                         False          0.86  \n",
              "1                                                         False          0.75  \n",
              "2    This is my second—and hopefully last—week trad...    False          0.75  \n",
              "3                                                         False          0.86  \n",
              "4                                                         False          0.96  \n",
              "..                                                 ...      ...           ...  \n",
              "792  Had a successful 20 day run up with a small $2...    False          0.95  \n",
              "793  Had a feeling we’d sell off hard for PCE even ...    False          0.96  \n",
              "794                                                       False          0.96  \n",
              "795                                                       False          0.92  \n",
              "796  Lot of people on WSB treat the Market like a c...    False          0.66  \n",
              "\n",
              "[797 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Parse are submission objects that we collected.\n",
        "fields = ('title',\n",
        "          'created_utc',\n",
        "          'id',\n",
        "          'is_original_content',\n",
        "          'link_flair_text',\n",
        "          'locked',\n",
        "          'name',\n",
        "          'num_comments',\n",
        "          'over_18',\n",
        "          'permalink',\n",
        "          'selftext',\n",
        "          'spoiler',\n",
        "          'upvote_ratio')\n",
        "list_of_submissions = []\n",
        "\n",
        "# Parse each submission into a dictionary of the lised fields.\n",
        "for submission in all_posts:\n",
        "    full = vars(submission)\n",
        "    sub_dict = {field:full[field] for field in fields}\n",
        "    list_of_submissions.append(sub_dict)\n",
        "\n",
        "# Create a python dataframe of these submissions.\n",
        "collected_data = pd.DataFrame.from_records(list_of_submissions)\n",
        "\n",
        "# Display the dataframe.\n",
        "display(collected_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWFn6XlM8BkV"
      },
      "source": [
        "### Saving Reddit Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the collected data to parquet format\n",
        "SUBMISSION_PARQUET_PATH = './data/wallstreetbets-collection.parquet'\n",
        "\n",
        "# Create a pyarrow schema for the data types.\n",
        "submission_schema = pyarrow.schema([\n",
        "    ('title', pyarrow.string()),\n",
        "    ('created_utc', pyarrow.float64()),\n",
        "    ('id', pyarrow.string()),\n",
        "    ('is_original_content', pyarrow.bool_()),\n",
        "    ('link_flair_text', pyarrow.string()),\n",
        "    ('locked', pyarrow.bool_()),\n",
        "    ('name', pyarrow.string()),\n",
        "    ('num_comments', pyarrow.int64()),\n",
        "    ('over_18', pyarrow.bool_()),\n",
        "    ('permalink', pyarrow.string()),\n",
        "    ('selftext', pyarrow.string()),\n",
        "    ('spoiler', pyarrow.bool_()),\n",
        "    ('upvote_ratio', pyarrow.float64()),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "leoYaEHt8BkV"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>id</th>\n",
              "      <th>is_original_content</th>\n",
              "      <th>link_flair_text</th>\n",
              "      <th>locked</th>\n",
              "      <th>name</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>over_18</th>\n",
              "      <th>permalink</th>\n",
              "      <th>selftext</th>\n",
              "      <th>spoiler</th>\n",
              "      <th>upvote_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nivea Along</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>False</td>\n",
              "      <td>YOLO</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0t4jk</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0t4jk/nivea_along/</td>\n",
              "      <td>After -7% yesterday and -10% today</td>\n",
              "      <td>False</td>\n",
              "      <td>0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Powell to Volatile Stock Market: You’re on You...</td>\n",
              "      <td>1.744836e+09</td>\n",
              "      <td>1k0unbq</td>\n",
              "      <td>False</td>\n",
              "      <td>News</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0unbq</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0unbq/powell_to_v...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Super sick timing</td>\n",
              "      <td>1.744835e+09</td>\n",
              "      <td>1k0umm6</td>\n",
              "      <td>False</td>\n",
              "      <td>Loss</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0umm6</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0umm6/super_sick_...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My second week trading options. SPY BAC and BABA</td>\n",
              "      <td>1.744835e+09</td>\n",
              "      <td>1k0ugf8</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0ugf8</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0ugf8/my_second_w...</td>\n",
              "      <td>This is my second—and hopefully last—week trad...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Don’t see this too often</td>\n",
              "      <td>1.744835e+09</td>\n",
              "      <td>1k0ubo1</td>\n",
              "      <td>False</td>\n",
              "      <td>Discussion</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0ubo1</td>\n",
              "      <td>11</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0ubo1/dont_see_th...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>793</th>\n",
              "      <td>Account Blew Up In One Day</td>\n",
              "      <td>1.743226e+09</td>\n",
              "      <td>1jmff4z</td>\n",
              "      <td>False</td>\n",
              "      <td>Loss</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jmff4z</td>\n",
              "      <td>106</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jmff4z/account_ble...</td>\n",
              "      <td>Had a successful 20 day run up with a small $2...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794</th>\n",
              "      <td>Pretty Good Friday</td>\n",
              "      <td>1.743223e+09</td>\n",
              "      <td>1jmei0h</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jmei0h</td>\n",
              "      <td>23</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jmei0h/pretty_good...</td>\n",
              "      <td>Had a feeling we’d sell off hard for PCE even ...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>Oracle to build cluster of 30,000 AMD MI355X GPUs</td>\n",
              "      <td>1.743214e+09</td>\n",
              "      <td>1jmbxap</td>\n",
              "      <td>False</td>\n",
              "      <td>News</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jmbxap</td>\n",
              "      <td>50</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jmbxap/oracle_to_b...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>299 to 5k. Baby gains but fuck NVDA</td>\n",
              "      <td>1.743210e+09</td>\n",
              "      <td>1jmamu6</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jmamu6</td>\n",
              "      <td>78</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jmamu6/299_to_5k_b...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>Hard Work and Patience Pays Off</td>\n",
              "      <td>1.743203e+09</td>\n",
              "      <td>1jm85ur</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jm85ur</td>\n",
              "      <td>47</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jm85ur/hard_work_a...</td>\n",
              "      <td>Lot of people on WSB treat the Market like a c...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.66</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>798 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 title   created_utc       id  \\\n",
              "0                                          Nivea Along  1.744832e+09  1k0t4jk   \n",
              "1    Powell to Volatile Stock Market: You’re on You...  1.744836e+09  1k0unbq   \n",
              "2                                    Super sick timing  1.744835e+09  1k0umm6   \n",
              "3     My second week trading options. SPY BAC and BABA  1.744835e+09  1k0ugf8   \n",
              "4                             Don’t see this too often  1.744835e+09  1k0ubo1   \n",
              "..                                                 ...           ...      ...   \n",
              "793                         Account Blew Up In One Day  1.743226e+09  1jmff4z   \n",
              "794                                 Pretty Good Friday  1.743223e+09  1jmei0h   \n",
              "795  Oracle to build cluster of 30,000 AMD MI355X GPUs  1.743214e+09  1jmbxap   \n",
              "796                299 to 5k. Baby gains but fuck NVDA  1.743210e+09  1jmamu6   \n",
              "797                    Hard Work and Patience Pays Off  1.743203e+09  1jm85ur   \n",
              "\n",
              "     is_original_content link_flair_text  locked        name  num_comments  \\\n",
              "0                  False            YOLO   False  t3_1k0t4jk             5   \n",
              "1                  False            News   False  t3_1k0unbq             2   \n",
              "2                  False            Loss   False  t3_1k0umm6             3   \n",
              "3                  False            Gain   False  t3_1k0ugf8             1   \n",
              "4                  False      Discussion   False  t3_1k0ubo1            11   \n",
              "..                   ...             ...     ...         ...           ...   \n",
              "793                False            Loss   False  t3_1jmff4z           106   \n",
              "794                False            Gain   False  t3_1jmei0h            23   \n",
              "795                False            News   False  t3_1jmbxap            50   \n",
              "796                False            Gain   False  t3_1jmamu6            78   \n",
              "797                False            Gain   False  t3_1jm85ur            47   \n",
              "\n",
              "     over_18                                          permalink  \\\n",
              "0      False    /r/wallstreetbets/comments/1k0t4jk/nivea_along/   \n",
              "1      False  /r/wallstreetbets/comments/1k0unbq/powell_to_v...   \n",
              "2      False  /r/wallstreetbets/comments/1k0umm6/super_sick_...   \n",
              "3      False  /r/wallstreetbets/comments/1k0ugf8/my_second_w...   \n",
              "4      False  /r/wallstreetbets/comments/1k0ubo1/dont_see_th...   \n",
              "..       ...                                                ...   \n",
              "793    False  /r/wallstreetbets/comments/1jmff4z/account_ble...   \n",
              "794    False  /r/wallstreetbets/comments/1jmei0h/pretty_good...   \n",
              "795    False  /r/wallstreetbets/comments/1jmbxap/oracle_to_b...   \n",
              "796    False  /r/wallstreetbets/comments/1jmamu6/299_to_5k_b...   \n",
              "797    False  /r/wallstreetbets/comments/1jm85ur/hard_work_a...   \n",
              "\n",
              "                                              selftext  spoiler  upvote_ratio  \n",
              "0                  After -7% yesterday and -10% today     False          0.67  \n",
              "1                                                         False          0.86  \n",
              "2                                                         False          0.75  \n",
              "3    This is my second—and hopefully last—week trad...    False          0.75  \n",
              "4                                                         False          0.86  \n",
              "..                                                 ...      ...           ...  \n",
              "793  Had a successful 20 day run up with a small $2...    False          0.95  \n",
              "794  Had a feeling we’d sell off hard for PCE even ...    False          0.96  \n",
              "795                                                       False          0.96  \n",
              "796                                                       False          0.92  \n",
              "797  Lot of people on WSB treat the Market like a c...    False          0.66  \n",
              "\n",
              "[798 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# If the parqet does not exist, create it.\n",
        "if not os.path.exists(SUBMISSION_PARQUET_PATH):\n",
        "    collected_data.to_parquet(SUBMISSION_PARQUET_PATH, engine='pyarrow', schema=submission_schema)\n",
        "\n",
        "# If the data file already exist, merge new data with the existing one.\n",
        "else:\n",
        "    old_parquet = pd.read_parquet(SUBMISSION_PARQUET_PATH, engine='pyarrow', schema=submission_schema)\n",
        "    new_parquet = pd.concat([old_parquet, collected_data])\n",
        "    new_parquet = new_parquet.drop_duplicates(subset=['id','title','created_utc','name','permalink'], keep='last').reset_index(drop=True)\n",
        "    new_parquet.to_parquet(SUBMISSION_PARQUET_PATH, engine='pyarrow', schema=submission_schema)\n",
        "\n",
        "# Use the new collected data to get comment stuff.\n",
        "SUBMISSION_PARQUET_PATH = './data/wallstreetbets-collection.parquet'\n",
        "submission_collection = pd.read_parquet(SUBMISSION_PARQUET_PATH, engine='pyarrow', schema=submission_schema)\n",
        "display(submission_collection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A52zTdg88BkV"
      },
      "source": [
        "## Part 3: Collecting Comments from Reddit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_K-voA38BkV"
      },
      "source": [
        "### Creating a database of reddit threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XXHu7mFu8BkV"
      },
      "outputs": [],
      "source": [
        "# Use the same methofology whih we used to collect submissions, but we'll add a parent submission id. and parent comment id.\n",
        "# Since the comment section can be very deep, we'll limit comments to a breadth of 10.\n",
        "# This may still be a lot more comments than we need for larger discussions.\n",
        "def extract_comments_from_submission(submission_id: str):\n",
        "    try:\n",
        "        submission = reddit.submission(id=submission_id)\n",
        "        submission.comments.replace_more(limit=10)  # Limit to 10 levels of comments\n",
        "        comments = []\n",
        "\n",
        "        for comment in submission.comments.list():\n",
        "            if isinstance(comment, praw.models.MoreComments):\n",
        "                continue\n",
        "\n",
        "            # NOTE: It looks like the top comment may be a user report. We'll ignore if is has certain text.\n",
        "            SKIPTEXT = '**User Report**'\n",
        "            if SKIPTEXT in comment.body:\n",
        "                continue\n",
        "\n",
        "            # Append the comment data to the list\n",
        "            comments.append({\n",
        "                'parent_post_id': submission_id,\n",
        "                'parent_comment_id': comment.parent_id,\n",
        "                'comment_id': comment.id,\n",
        "                'author': str(comment.author),\n",
        "                'created_utc': comment.created_utc,\n",
        "                'score': comment.score,\n",
        "                'body': comment.body\n",
        "            })\n",
        "\n",
        "        return comments\n",
        "\n",
        "    except Exception as e:\n",
        "        # Get the HTTP error code if available\n",
        "        if hasattr(e, 'response') and e.response is not None:\n",
        "            error_code = e.response.status_code\n",
        "            print(f\"HTTP Error {error_code} while fetching comments for submission {submission_id}\")\n",
        "        else:\n",
        "            error_code = None\n",
        "\n",
        "        # Print the an erroor message and return nothing.\n",
        "        print(f\"Error fetching comments for submission {submission_id}: {e}\")\n",
        "        return []\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gYeljFKM8BkV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission ID: 1k0t4jk\n",
            "Title: Nivea Along\n",
            "Number of comments: 6\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>parent_post_id</th>\n",
              "      <th>parent_comment_id</th>\n",
              "      <th>comment_id</th>\n",
              "      <th>author</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>score</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t3_1k0t4jk</td>\n",
              "      <td>mngn956</td>\n",
              "      <td>Alert_Barber_3105</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>6</td>\n",
              "      <td>The skin cream?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t3_1k0t4jk</td>\n",
              "      <td>mngmxdi</td>\n",
              "      <td>chrissurra</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>4</td>\n",
              "      <td>You mean Neveah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t3_1k0t4jk</td>\n",
              "      <td>mngoka2</td>\n",
              "      <td>Reasonable_Roger</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>Psoriasis calls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t1_mngn956</td>\n",
              "      <td>mngnj1n</td>\n",
              "      <td>Own-Foundation3873</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>pow till it creams</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t1_mngmxdi</td>\n",
              "      <td>mngnbpk</td>\n",
              "      <td>Own-Foundation3873</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>yesss sir</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  parent_post_id parent_comment_id comment_id              author  \\\n",
              "0        1k0t4jk        t3_1k0t4jk    mngn956   Alert_Barber_3105   \n",
              "1        1k0t4jk        t3_1k0t4jk    mngmxdi          chrissurra   \n",
              "2        1k0t4jk        t3_1k0t4jk    mngoka2    Reasonable_Roger   \n",
              "3        1k0t4jk        t1_mngn956    mngnj1n  Own-Foundation3873   \n",
              "4        1k0t4jk        t1_mngmxdi    mngnbpk  Own-Foundation3873   \n",
              "\n",
              "    created_utc  score                body  \n",
              "0  1.744832e+09      6     The skin cream?  \n",
              "1  1.744832e+09      4     You mean Neveah  \n",
              "2  1.744832e+09      1     Psoriasis calls  \n",
              "3  1.744832e+09      1  pow till it creams  \n",
              "4  1.744832e+09      1           yesss sir  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Show the results from one submission's comments\n",
        "submission_id = submission_collection.iloc[0]['id']\n",
        "\n",
        "# How many actual comments are there for this submission?\n",
        "submission = reddit.submission(id=submission_id)\n",
        "print(f\"Submission ID: {submission_id}\")\n",
        "print(f\"Title: {submission.title}\")\n",
        "print(f\"Number of comments: {submission.num_comments}\")\n",
        "\n",
        "# Get the comments for the submission\n",
        "results = extract_comments_from_submission(submission_id)\n",
        "\n",
        "# Create a dataframe of the comments\n",
        "comments_df = pd.DataFrame(results)\n",
        "\n",
        "# Display the comments dataframe\n",
        "display(comments_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vB3PNPj-8BkV"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>parent_post_id</th>\n",
              "      <th>parent_comment_id</th>\n",
              "      <th>comment_id</th>\n",
              "      <th>author</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>score</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t3_1k0t4jk</td>\n",
              "      <td>mngn956</td>\n",
              "      <td>Alert_Barber_3105</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>6</td>\n",
              "      <td>The skin cream?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t3_1k0t4jk</td>\n",
              "      <td>mngmxdi</td>\n",
              "      <td>chrissurra</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>4</td>\n",
              "      <td>You mean Neveah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t3_1k0t4jk</td>\n",
              "      <td>mngoka2</td>\n",
              "      <td>Reasonable_Roger</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>Psoriasis calls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t1_mngn956</td>\n",
              "      <td>mngnj1n</td>\n",
              "      <td>Own-Foundation3873</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>pow till it creams</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t1_mngmxdi</td>\n",
              "      <td>mngnbpk</td>\n",
              "      <td>Own-Foundation3873</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>yesss sir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151632</th>\n",
              "      <td>1jm85ur</td>\n",
              "      <td>t1_mkehvqw</td>\n",
              "      <td>mkejgzy</td>\n",
              "      <td>CultureForsaken3762</td>\n",
              "      <td>1.743277e+09</td>\n",
              "      <td>2</td>\n",
              "      <td>The Little Book That Beats the Market - Joel G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151633</th>\n",
              "      <td>1jm85ur</td>\n",
              "      <td>t1_mka50c0</td>\n",
              "      <td>mkfszsb</td>\n",
              "      <td>Lemonibluff</td>\n",
              "      <td>1.743292e+09</td>\n",
              "      <td>3</td>\n",
              "      <td>Agreed. The fight is to become the EveryGamble...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151634</th>\n",
              "      <td>1jm85ur</td>\n",
              "      <td>t1_mkejgzy</td>\n",
              "      <td>mkel24x</td>\n",
              "      <td>Stamperdoodle1</td>\n",
              "      <td>1.743277e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>amazing recommendation, thank you so much!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151635</th>\n",
              "      <td>1jm85ur</td>\n",
              "      <td>t1_mkel24x</td>\n",
              "      <td>mkely5t</td>\n",
              "      <td>CultureForsaken3762</td>\n",
              "      <td>1.743278e+09</td>\n",
              "      <td>2</td>\n",
              "      <td>My pleasure.  You arent “not smart enough”.  Y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151636</th>\n",
              "      <td>1jm85ur</td>\n",
              "      <td>t1_mkely5t</td>\n",
              "      <td>mketyvm</td>\n",
              "      <td>Stamperdoodle1</td>\n",
              "      <td>1.743280e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>You're the best, thank you for being awesome.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151637 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       parent_post_id parent_comment_id comment_id               author  \\\n",
              "0             1k0t4jk        t3_1k0t4jk    mngn956    Alert_Barber_3105   \n",
              "1             1k0t4jk        t3_1k0t4jk    mngmxdi           chrissurra   \n",
              "2             1k0t4jk        t3_1k0t4jk    mngoka2     Reasonable_Roger   \n",
              "3             1k0t4jk        t1_mngn956    mngnj1n   Own-Foundation3873   \n",
              "4             1k0t4jk        t1_mngmxdi    mngnbpk   Own-Foundation3873   \n",
              "...               ...               ...        ...                  ...   \n",
              "151632        1jm85ur        t1_mkehvqw    mkejgzy  CultureForsaken3762   \n",
              "151633        1jm85ur        t1_mka50c0    mkfszsb          Lemonibluff   \n",
              "151634        1jm85ur        t1_mkejgzy    mkel24x       Stamperdoodle1   \n",
              "151635        1jm85ur        t1_mkel24x    mkely5t  CultureForsaken3762   \n",
              "151636        1jm85ur        t1_mkely5t    mketyvm       Stamperdoodle1   \n",
              "\n",
              "         created_utc  score                                               body  \n",
              "0       1.744832e+09      6                                    The skin cream?  \n",
              "1       1.744832e+09      4                                    You mean Neveah  \n",
              "2       1.744832e+09      1                                    Psoriasis calls  \n",
              "3       1.744832e+09      1                                 pow till it creams  \n",
              "4       1.744832e+09      1                                          yesss sir  \n",
              "...              ...    ...                                                ...  \n",
              "151632  1.743277e+09      2  The Little Book That Beats the Market - Joel G...  \n",
              "151633  1.743292e+09      3  Agreed. The fight is to become the EveryGamble...  \n",
              "151634  1.743277e+09      1         amazing recommendation, thank you so much!  \n",
              "151635  1.743278e+09      2  My pleasure.  You arent “not smart enough”.  Y...  \n",
              "151636  1.743280e+09      1      You're the best, thank you for being awesome.  \n",
              "\n",
              "[151637 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Collect the comments for all the submissions.\n",
        "all_comments = []\n",
        "for submission in submission_collection['id']:\n",
        "    comments = extract_comments_from_submission(submission)\n",
        "    all_comments.extend(comments)\n",
        "    time.sleep(1)  # Optional delay to avoid rate limits\n",
        "\n",
        "# Create a python dataframe of these comments.\n",
        "comments_df = pd.DataFrame.from_records(all_comments)\n",
        "display(comments_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the collected data to parquet format\n",
        "COMMENT_PARQUET_PATH = './data/wallstreetbets-comment-collection.parquet'\n",
        "\n",
        "# Create a pyarrow schema for the comment data\n",
        "comment_schema = pyarrow.schema([\n",
        "    ('parent_post_id', pyarrow.string()),\n",
        "    ('parent_comment_id', pyarrow.string()),\n",
        "    ('comment_id', pyarrow.string()),\n",
        "    ('author', pyarrow.string()),\n",
        "    ('created_utc', pyarrow.float64()),\n",
        "    ('score', pyarrow.int64()),\n",
        "    ('body', pyarrow.string())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hNVWhQB_8BkW"
      },
      "outputs": [],
      "source": [
        "# Write the comments to parquet file. If it exists, append to it.\n",
        "if not os.path.exists(COMMENT_PARQUET_PATH):\n",
        "    comments_df.to_parquet(COMMENT_PARQUET_PATH, engine='pyarrow', schema=comment_schema)\n",
        "else:\n",
        "    old_parquet = pd.read_parquet(COMMENT_PARQUET_PATH, engine='pyarrow', schema=comment_schema)\n",
        "    new_parquet = pd.concat([old_parquet, comments_df])\n",
        "    new_parquet = new_parquet.drop_duplicates(subset=['parent_post_id','parent_comment_id','author','created_utc'], keep='last').reset_index(drop=True)\n",
        "    new_parquet.to_parquet(COMMENT_PARQUET_PATH, engine='pyarrow', schema=comment_schema)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
