{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Collecting Reddit Data from r/WallStreetBets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mqH72oV8BkP"
      },
      "source": [
        "## Part 1: Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoSNYlmE8BkQ"
      },
      "source": [
        "### Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNHmHw-T8BkQ",
        "outputId": "5682a658-2c7f-4d24-e12c-866f8ade2b85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: praw in ./venv/lib/python3.12/site-packages (7.8.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in ./venv/lib/python3.12/site-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in ./venv/lib/python3.12/site-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in ./venv/lib/python3.12/site-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in ./venv/lib/python3.12/site-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.1.31)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pyarrow in ./venv/lib/python3.12/site-packages (19.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: python-dotenv in ./venv/lib/python3.12/site-packages (1.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install the packages if they don't exist.\n",
        "%pip install praw\n",
        "%pip install pyarrow\n",
        "%pip install python-dotenv\n",
        "\n",
        "# Import Packages\n",
        "import praw, time, os, pyarrow\n",
        "from IPython.display import display\n",
        "from dotenv import load_dotenv, dotenv_values\n",
        "from requests import Session\n",
        "import pandas as pd\n",
        "from IPython import get_ipython\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv('.env')\n",
        "config = dotenv_values()\n",
        "\n",
        "# Get config from colab or other environment.\n",
        "def is_colab():\n",
        "    return get_ipython().__class__.__module__ == \"google.colab._shell\"\n",
        "\n",
        "if is_colab():\n",
        "    from google.colab import userdata\n",
        "    config = {}\n",
        "    config['CLIENT_SECRET'] = userdata.get('CLIENT_SECRET')\n",
        "    config['CLIENT_ID'] = userdata.get('CLIENT_ID')\n",
        "    config['NAME'] = userdata.get('NAME')\n",
        "    config['REDIRECT_URI'] = userdata.get('REDIRECT_URI')\n",
        "    config['USERNAME'] = userdata.get('USERNAME')\n",
        "    config['PASSWORD'] = userdata.get('PASSWORD')\n",
        "\n",
        "else:\n",
        "    load_dotenv('.env')\n",
        "    config = dotenv_values()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ6nQKwq8BkR"
      },
      "source": [
        "## Part 2: Collecting Submissions from Reddit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIqcjmZA8BkR"
      },
      "source": [
        "### Open Reddit Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "mkZtaceY8BkR",
        "outputId": "a1b8a895-f6f3-422f-dac8-b7794d675fe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully logged in to Reddit!\n",
            "Logged in as: u/GregorybLafayetteML\n"
          ]
        }
      ],
      "source": [
        "# Create a custom session with a timeout\n",
        "session = Session()\n",
        "session.headers.update({'User-Agent': 'praw'})\n",
        "session.timeout = 10  # Set a timeout of 10 seconds\n",
        "\n",
        "# Login to Reddit using PRAW\n",
        "reddit = praw.Reddit(\n",
        "    client_id=config['CLIENT_ID'],\n",
        "    client_secret=config['CLIENT_SECRET'],\n",
        "    requestor_kwargs={\"session\": session},\n",
        "    username=config['USERNAME'],\n",
        "    password=config['PASSWORD'],\n",
        "    user_agent=\"CS470 ML Project Access by u/GregorybLafayetteML\"\n",
        ")\n",
        "\n",
        "# Add some peripheral config data\n",
        "reddit.config.log_requests = 1\n",
        "reddit.config.store_json_result = True\n",
        "\n",
        "# Test the connection\n",
        "try:\n",
        "    username = reddit.user.me()\n",
        "    print(\"Successfully logged in to Reddit!\")\n",
        "    print(f\"Logged in as: u/{username}\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to log in: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk6FGRfK8BkS"
      },
      "source": [
        "### Accessing Reddit Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnIgfIks8BkT"
      },
      "source": [
        "To access reddit posts, we'll need send a request with the number of post we want to get. The following example finds the top 10 hottest posts on the u/wallstreetbets subreddit. We'll show the post title, score, flair, and URL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MMebUrT98BkT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 hot posts from r/wallstreetbets:\n",
            "Title: Weekly Earnings Thread 4/14 - 4/18, Score: 208, Flair: Earnings Thread, URL: https://i.redd.it/b51iqmecn7ue1.jpeg\n",
            "Title: What Are Your Moves Tomorrow, April 17, 2025, Score: 65, Flair: Daily Discussion, URL: https://www.reddit.com/r/wallstreetbets/comments/1k0tt5k/what_are_your_moves_tomorrow_april_17_2025/\n",
            "Title: Powell indicates tariffs could pose a challenge for the Fed between controlling inflation and supporting economic growth, Score: 5035, Flair: News, URL: https://www.cnbc.com/2025/04/16/powell-indicates-tariffs-could-pose-a-two-pronged-policy-challenge-for-the-fed-.html\n",
            "Title: Powellâ€™s futureâ€¦., Score: 1506, Flair: Meme, URL: https://v.redd.it/c0gaopbap8ve1\n",
            "Title: Just doubled down on my bet ðŸ˜¬ðŸ˜¬ðŸ˜¬, Score: 1933, Flair: YOLO, URL: https://i.redd.it/kirarknsw7ve1.jpeg\n",
            "Title: Retail sales surged in March as Americans rushed to beat Trumpâ€™s tariffs, Score: 2221, Flair: News, URL: https://www.reddit.com/r/wallstreetbets/comments/1k0jvyb/retail_sales_surged_in_march_as_americans_rushed/\n",
            "Title: White House: China now faces up to a 245% tariff on imports to the United States as a result of its retaliatory actions., Score: 21016, Flair: News, URL: https://www.reddit.com/r/wallstreetbets/comments/1k0b996/white_house_china_now_faces_up_to_a_245_tariff_on/\n",
            "Title: A reminder that Powell speaks today, get yourselves ready, Score: 4015, Flair: Discussion, URL: https://i.redd.it/ssjmpdi7y5ve1.jpeg\n",
            "Title: Ominous, Score: 533, Flair: Discussion, URL: https://i.redd.it/ovlhyl4939ve1.png\n",
            "Title: There wonâ€™t be a trade deal between US and China, Score: 2880, Flair: Discussion, URL: https://www.reddit.com/r/wallstreetbets/comments/1k0e00n/there_wont_be_a_trade_deal_between_us_and_china/\n"
          ]
        }
      ],
      "source": [
        "top_posts = reddit.subreddit('wallstreetbets').hot(limit=10)\n",
        "print(\"Top 10 hot posts from r/wallstreetbets:\")\n",
        "for post in top_posts:\n",
        "    print(f\"Title: {post.title}, Score: {post.score}, Flair: {post.link_flair_text}, URL: {post.url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IxVa5Xi8BkU"
      },
      "source": [
        "For this project, we'll need far more than ten posts at a time. The reddit API will limit our access to 100 posts at a time. Fortunately, the api uses a ListingGenerator which allows us to access our metered connection in sequential blocks. The following example shows how we can utilize this behavior, grabbing blocks of 100 posts at a time. In our example, we'll grab blocks of posts until we reach 5000 posts or our access times out. Notice that the procedure ends early with around 750-800 posts collected. The results are sparce, because our connection either timed out or was metered down by reddit. The latter option is more likely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WG2zyxFP8BkU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No more posts to fetch.\n",
            "Fetched 797 posts in total.\n"
          ]
        }
      ],
      "source": [
        "# Access the subreddit\n",
        "subreddit = reddit.subreddit(\"wallstreetbets\")\n",
        "\n",
        "# Initialize variables\n",
        "batch_size = 50 # Number of posts per batch\n",
        "total_posts = 5000  # Total number of posts to fetch\n",
        "all_posts = []  # To store all the retrieved posts\n",
        "after = None  # To keep track of the last post for pagination\n",
        "\n",
        "# Fetch posts in batches\n",
        "while len(all_posts) < total_posts:\n",
        "    # Fetch the next batch of posts\n",
        "    submissions = subreddit.new(limit=batch_size, params={\"after\": after})\n",
        "\n",
        "    batch_posts = []\n",
        "    for submission in submissions:\n",
        "        batch_posts.append(submission)\n",
        "\n",
        "        # Update the `after` variable with the last submission's fullname\n",
        "        after = submission.fullname\n",
        "\n",
        "    # Add the batch to the main list\n",
        "    all_posts.extend(batch_posts)\n",
        "\n",
        "    # Exit loop if no more posts are available\n",
        "    if not batch_posts:\n",
        "        print(\"No more posts to fetch.\")\n",
        "        break\n",
        "\n",
        "    # Optional delay to avoid rate limits\n",
        "    time.sleep(5)  # Adjust the delay as necessary\n",
        "\n",
        "# Process the data (example: print the total number of posts fetched)\n",
        "print(f\"Fetched {len(all_posts)} posts in total.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_4N4b2q8BkU"
      },
      "source": [
        "Now that we have collected a large portion of posts/submssions, we'll parse the results and construct a dataframe with this data. We're going to collect more fields from this data than we might need right now, avoiding data limitations in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "69crArfG8BkU"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>id</th>\n",
              "      <th>is_original_content</th>\n",
              "      <th>link_flair_text</th>\n",
              "      <th>locked</th>\n",
              "      <th>name</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>over_18</th>\n",
              "      <th>permalink</th>\n",
              "      <th>selftext</th>\n",
              "      <th>spoiler</th>\n",
              "      <th>upvote_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Powell to Volatile Stock Market: Youâ€™re on You...</td>\n",
              "      <td>1.744836e+09</td>\n",
              "      <td>1k0unbq</td>\n",
              "      <td>False</td>\n",
              "      <td>News</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0unbq</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0unbq/powell_to_v...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Super sick timing</td>\n",
              "      <td>1.744835e+09</td>\n",
              "      <td>1k0umm6</td>\n",
              "      <td>False</td>\n",
              "      <td>Loss</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0umm6</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0umm6/super_sick_...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>My second week trading options. SPY BAC and BABA</td>\n",
              "      <td>1.744835e+09</td>\n",
              "      <td>1k0ugf8</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0ugf8</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0ugf8/my_second_w...</td>\n",
              "      <td>This is my secondâ€”and hopefully lastâ€”week trad...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Donâ€™t see this too often</td>\n",
              "      <td>1.744835e+09</td>\n",
              "      <td>1k0ubo1</td>\n",
              "      <td>False</td>\n",
              "      <td>Discussion</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0ubo1</td>\n",
              "      <td>11</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0ubo1/dont_see_th...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I was about to rope and then +97k</td>\n",
              "      <td>1.744834e+09</td>\n",
              "      <td>1k0u286</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0u286</td>\n",
              "      <td>10</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0u286/i_was_about...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>792</th>\n",
              "      <td>Account Blew Up In One Day</td>\n",
              "      <td>1.743226e+09</td>\n",
              "      <td>1jmff4z</td>\n",
              "      <td>False</td>\n",
              "      <td>Loss</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jmff4z</td>\n",
              "      <td>106</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jmff4z/account_ble...</td>\n",
              "      <td>Had a successful 20 day run up with a small $2...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>793</th>\n",
              "      <td>Pretty Good Friday</td>\n",
              "      <td>1.743223e+09</td>\n",
              "      <td>1jmei0h</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jmei0h</td>\n",
              "      <td>23</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jmei0h/pretty_good...</td>\n",
              "      <td>Had a feeling weâ€™d sell off hard for PCE even ...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794</th>\n",
              "      <td>Oracle to build cluster of 30,000 AMD MI355X GPUs</td>\n",
              "      <td>1.743214e+09</td>\n",
              "      <td>1jmbxap</td>\n",
              "      <td>False</td>\n",
              "      <td>News</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jmbxap</td>\n",
              "      <td>50</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jmbxap/oracle_to_b...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>299 to 5k. Baby gains but fuck NVDA</td>\n",
              "      <td>1.743210e+09</td>\n",
              "      <td>1jmamu6</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jmamu6</td>\n",
              "      <td>78</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jmamu6/299_to_5k_b...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>Hard Work and Patience Pays Off</td>\n",
              "      <td>1.743203e+09</td>\n",
              "      <td>1jm85ur</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jm85ur</td>\n",
              "      <td>47</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jm85ur/hard_work_a...</td>\n",
              "      <td>Lot of people on WSB treat the Market like a c...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.66</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>797 rows Ã— 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 title   created_utc       id  \\\n",
              "0    Powell to Volatile Stock Market: Youâ€™re on You...  1.744836e+09  1k0unbq   \n",
              "1                                    Super sick timing  1.744835e+09  1k0umm6   \n",
              "2     My second week trading options. SPY BAC and BABA  1.744835e+09  1k0ugf8   \n",
              "3                             Donâ€™t see this too often  1.744835e+09  1k0ubo1   \n",
              "4                    I was about to rope and then +97k  1.744834e+09  1k0u286   \n",
              "..                                                 ...           ...      ...   \n",
              "792                         Account Blew Up In One Day  1.743226e+09  1jmff4z   \n",
              "793                                 Pretty Good Friday  1.743223e+09  1jmei0h   \n",
              "794  Oracle to build cluster of 30,000 AMD MI355X GPUs  1.743214e+09  1jmbxap   \n",
              "795                299 to 5k. Baby gains but fuck NVDA  1.743210e+09  1jmamu6   \n",
              "796                    Hard Work and Patience Pays Off  1.743203e+09  1jm85ur   \n",
              "\n",
              "     is_original_content link_flair_text  locked        name  num_comments  \\\n",
              "0                  False            News   False  t3_1k0unbq             2   \n",
              "1                  False            Loss   False  t3_1k0umm6             3   \n",
              "2                  False            Gain   False  t3_1k0ugf8             1   \n",
              "3                  False      Discussion   False  t3_1k0ubo1            11   \n",
              "4                  False            Gain   False  t3_1k0u286            10   \n",
              "..                   ...             ...     ...         ...           ...   \n",
              "792                False            Loss   False  t3_1jmff4z           106   \n",
              "793                False            Gain   False  t3_1jmei0h            23   \n",
              "794                False            News   False  t3_1jmbxap            50   \n",
              "795                False            Gain   False  t3_1jmamu6            78   \n",
              "796                False            Gain   False  t3_1jm85ur            47   \n",
              "\n",
              "     over_18                                          permalink  \\\n",
              "0      False  /r/wallstreetbets/comments/1k0unbq/powell_to_v...   \n",
              "1      False  /r/wallstreetbets/comments/1k0umm6/super_sick_...   \n",
              "2      False  /r/wallstreetbets/comments/1k0ugf8/my_second_w...   \n",
              "3      False  /r/wallstreetbets/comments/1k0ubo1/dont_see_th...   \n",
              "4      False  /r/wallstreetbets/comments/1k0u286/i_was_about...   \n",
              "..       ...                                                ...   \n",
              "792    False  /r/wallstreetbets/comments/1jmff4z/account_ble...   \n",
              "793    False  /r/wallstreetbets/comments/1jmei0h/pretty_good...   \n",
              "794    False  /r/wallstreetbets/comments/1jmbxap/oracle_to_b...   \n",
              "795    False  /r/wallstreetbets/comments/1jmamu6/299_to_5k_b...   \n",
              "796    False  /r/wallstreetbets/comments/1jm85ur/hard_work_a...   \n",
              "\n",
              "                                              selftext  spoiler  upvote_ratio  \n",
              "0                                                         False          0.86  \n",
              "1                                                         False          0.75  \n",
              "2    This is my secondâ€”and hopefully lastâ€”week trad...    False          0.75  \n",
              "3                                                         False          0.86  \n",
              "4                                                         False          0.96  \n",
              "..                                                 ...      ...           ...  \n",
              "792  Had a successful 20 day run up with a small $2...    False          0.95  \n",
              "793  Had a feeling weâ€™d sell off hard for PCE even ...    False          0.96  \n",
              "794                                                       False          0.96  \n",
              "795                                                       False          0.92  \n",
              "796  Lot of people on WSB treat the Market like a c...    False          0.66  \n",
              "\n",
              "[797 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Parse are submission objects that we collected.\n",
        "fields = ('title',\n",
        "          'created_utc',\n",
        "          'id',\n",
        "          'is_original_content',\n",
        "          'link_flair_text',\n",
        "          'locked',\n",
        "          'name',\n",
        "          'num_comments',\n",
        "          'over_18',\n",
        "          'permalink',\n",
        "          'selftext',\n",
        "          'spoiler',\n",
        "          'upvote_ratio')\n",
        "list_of_submissions = []\n",
        "\n",
        "# Parse each submission into a dictionary of the lised fields.\n",
        "for submission in all_posts:\n",
        "    full = vars(submission)\n",
        "    sub_dict = {field:full[field] for field in fields}\n",
        "    list_of_submissions.append(sub_dict)\n",
        "\n",
        "# Create a python dataframe of these submissions.\n",
        "collected_data = pd.DataFrame.from_records(list_of_submissions)\n",
        "\n",
        "# Display the dataframe.\n",
        "display(collected_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWFn6XlM8BkV"
      },
      "source": [
        "### Saving Reddit Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the collected data to parquet format\n",
        "SUBMISSION_PARQUET_PATH = './data/wallstreetbets-collection.parquet'\n",
        "\n",
        "# Create a pyarrow schema for the data types.\n",
        "submission_schema = pyarrow.schema([\n",
        "    ('title', pyarrow.string()),\n",
        "    ('created_utc', pyarrow.float64()),\n",
        "    ('id', pyarrow.string()),\n",
        "    ('is_original_content', pyarrow.bool_()),\n",
        "    ('link_flair_text', pyarrow.string()),\n",
        "    ('locked', pyarrow.bool_()),\n",
        "    ('name', pyarrow.string()),\n",
        "    ('num_comments', pyarrow.int64()),\n",
        "    ('over_18', pyarrow.bool_()),\n",
        "    ('permalink', pyarrow.string()),\n",
        "    ('selftext', pyarrow.string()),\n",
        "    ('spoiler', pyarrow.bool_()),\n",
        "    ('upvote_ratio', pyarrow.float64()),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "leoYaEHt8BkV"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>id</th>\n",
              "      <th>is_original_content</th>\n",
              "      <th>link_flair_text</th>\n",
              "      <th>locked</th>\n",
              "      <th>name</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>over_18</th>\n",
              "      <th>permalink</th>\n",
              "      <th>selftext</th>\n",
              "      <th>spoiler</th>\n",
              "      <th>upvote_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nivea Along</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>False</td>\n",
              "      <td>YOLO</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0t4jk</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0t4jk/nivea_along/</td>\n",
              "      <td>After -7% yesterday and -10% today</td>\n",
              "      <td>False</td>\n",
              "      <td>0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Powell to Volatile Stock Market: Youâ€™re on You...</td>\n",
              "      <td>1.744836e+09</td>\n",
              "      <td>1k0unbq</td>\n",
              "      <td>False</td>\n",
              "      <td>News</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0unbq</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0unbq/powell_to_v...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Super sick timing</td>\n",
              "      <td>1.744835e+09</td>\n",
              "      <td>1k0umm6</td>\n",
              "      <td>False</td>\n",
              "      <td>Loss</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0umm6</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0umm6/super_sick_...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My second week trading options. SPY BAC and BABA</td>\n",
              "      <td>1.744835e+09</td>\n",
              "      <td>1k0ugf8</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0ugf8</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0ugf8/my_second_w...</td>\n",
              "      <td>This is my secondâ€”and hopefully lastâ€”week trad...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Donâ€™t see this too often</td>\n",
              "      <td>1.744835e+09</td>\n",
              "      <td>1k0ubo1</td>\n",
              "      <td>False</td>\n",
              "      <td>Discussion</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1k0ubo1</td>\n",
              "      <td>11</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1k0ubo1/dont_see_th...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>793</th>\n",
              "      <td>Account Blew Up In One Day</td>\n",
              "      <td>1.743226e+09</td>\n",
              "      <td>1jmff4z</td>\n",
              "      <td>False</td>\n",
              "      <td>Loss</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jmff4z</td>\n",
              "      <td>106</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jmff4z/account_ble...</td>\n",
              "      <td>Had a successful 20 day run up with a small $2...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794</th>\n",
              "      <td>Pretty Good Friday</td>\n",
              "      <td>1.743223e+09</td>\n",
              "      <td>1jmei0h</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jmei0h</td>\n",
              "      <td>23</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jmei0h/pretty_good...</td>\n",
              "      <td>Had a feeling weâ€™d sell off hard for PCE even ...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>Oracle to build cluster of 30,000 AMD MI355X GPUs</td>\n",
              "      <td>1.743214e+09</td>\n",
              "      <td>1jmbxap</td>\n",
              "      <td>False</td>\n",
              "      <td>News</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jmbxap</td>\n",
              "      <td>50</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jmbxap/oracle_to_b...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>299 to 5k. Baby gains but fuck NVDA</td>\n",
              "      <td>1.743210e+09</td>\n",
              "      <td>1jmamu6</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jmamu6</td>\n",
              "      <td>78</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jmamu6/299_to_5k_b...</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>Hard Work and Patience Pays Off</td>\n",
              "      <td>1.743203e+09</td>\n",
              "      <td>1jm85ur</td>\n",
              "      <td>False</td>\n",
              "      <td>Gain</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_1jm85ur</td>\n",
              "      <td>47</td>\n",
              "      <td>False</td>\n",
              "      <td>/r/wallstreetbets/comments/1jm85ur/hard_work_a...</td>\n",
              "      <td>Lot of people on WSB treat the Market like a c...</td>\n",
              "      <td>False</td>\n",
              "      <td>0.66</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>798 rows Ã— 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 title   created_utc       id  \\\n",
              "0                                          Nivea Along  1.744832e+09  1k0t4jk   \n",
              "1    Powell to Volatile Stock Market: Youâ€™re on You...  1.744836e+09  1k0unbq   \n",
              "2                                    Super sick timing  1.744835e+09  1k0umm6   \n",
              "3     My second week trading options. SPY BAC and BABA  1.744835e+09  1k0ugf8   \n",
              "4                             Donâ€™t see this too often  1.744835e+09  1k0ubo1   \n",
              "..                                                 ...           ...      ...   \n",
              "793                         Account Blew Up In One Day  1.743226e+09  1jmff4z   \n",
              "794                                 Pretty Good Friday  1.743223e+09  1jmei0h   \n",
              "795  Oracle to build cluster of 30,000 AMD MI355X GPUs  1.743214e+09  1jmbxap   \n",
              "796                299 to 5k. Baby gains but fuck NVDA  1.743210e+09  1jmamu6   \n",
              "797                    Hard Work and Patience Pays Off  1.743203e+09  1jm85ur   \n",
              "\n",
              "     is_original_content link_flair_text  locked        name  num_comments  \\\n",
              "0                  False            YOLO   False  t3_1k0t4jk             5   \n",
              "1                  False            News   False  t3_1k0unbq             2   \n",
              "2                  False            Loss   False  t3_1k0umm6             3   \n",
              "3                  False            Gain   False  t3_1k0ugf8             1   \n",
              "4                  False      Discussion   False  t3_1k0ubo1            11   \n",
              "..                   ...             ...     ...         ...           ...   \n",
              "793                False            Loss   False  t3_1jmff4z           106   \n",
              "794                False            Gain   False  t3_1jmei0h            23   \n",
              "795                False            News   False  t3_1jmbxap            50   \n",
              "796                False            Gain   False  t3_1jmamu6            78   \n",
              "797                False            Gain   False  t3_1jm85ur            47   \n",
              "\n",
              "     over_18                                          permalink  \\\n",
              "0      False    /r/wallstreetbets/comments/1k0t4jk/nivea_along/   \n",
              "1      False  /r/wallstreetbets/comments/1k0unbq/powell_to_v...   \n",
              "2      False  /r/wallstreetbets/comments/1k0umm6/super_sick_...   \n",
              "3      False  /r/wallstreetbets/comments/1k0ugf8/my_second_w...   \n",
              "4      False  /r/wallstreetbets/comments/1k0ubo1/dont_see_th...   \n",
              "..       ...                                                ...   \n",
              "793    False  /r/wallstreetbets/comments/1jmff4z/account_ble...   \n",
              "794    False  /r/wallstreetbets/comments/1jmei0h/pretty_good...   \n",
              "795    False  /r/wallstreetbets/comments/1jmbxap/oracle_to_b...   \n",
              "796    False  /r/wallstreetbets/comments/1jmamu6/299_to_5k_b...   \n",
              "797    False  /r/wallstreetbets/comments/1jm85ur/hard_work_a...   \n",
              "\n",
              "                                              selftext  spoiler  upvote_ratio  \n",
              "0                  After -7% yesterday and -10% today     False          0.67  \n",
              "1                                                         False          0.86  \n",
              "2                                                         False          0.75  \n",
              "3    This is my secondâ€”and hopefully lastâ€”week trad...    False          0.75  \n",
              "4                                                         False          0.86  \n",
              "..                                                 ...      ...           ...  \n",
              "793  Had a successful 20 day run up with a small $2...    False          0.95  \n",
              "794  Had a feeling weâ€™d sell off hard for PCE even ...    False          0.96  \n",
              "795                                                       False          0.96  \n",
              "796                                                       False          0.92  \n",
              "797  Lot of people on WSB treat the Market like a c...    False          0.66  \n",
              "\n",
              "[798 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# If the parqet does not exist, create it.\n",
        "if not os.path.exists(SUBMISSION_PARQUET_PATH):\n",
        "    collected_data.to_parquet(SUBMISSION_PARQUET_PATH, engine='pyarrow', schema=submission_schema)\n",
        "\n",
        "# If the data file already exist, merge new data with the existing one.\n",
        "else:\n",
        "    old_parquet = pd.read_parquet(SUBMISSION_PARQUET_PATH, engine='pyarrow', schema=submission_schema)\n",
        "    new_parquet = pd.concat([old_parquet, collected_data])\n",
        "    new_parquet = new_parquet.drop_duplicates(subset=['id','title','created_utc','name','permalink'], keep='last').reset_index(drop=True)\n",
        "    new_parquet.to_parquet(SUBMISSION_PARQUET_PATH, engine='pyarrow', schema=submission_schema)\n",
        "\n",
        "# Use the new collected data to get comment stuff.\n",
        "SUBMISSION_PARQUET_PATH = './data/wallstreetbets-collection.parquet'\n",
        "submission_collection = pd.read_parquet(SUBMISSION_PARQUET_PATH, engine='pyarrow', schema=submission_schema)\n",
        "display(submission_collection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A52zTdg88BkV"
      },
      "source": [
        "## Part 3: Collecting Comments from Reddit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_K-voA38BkV"
      },
      "source": [
        "### Creating a database of reddit threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XXHu7mFu8BkV"
      },
      "outputs": [],
      "source": [
        "# Use the same methofology whih we used to collect submissions, but we'll add a parent submission id. and parent comment id.\n",
        "# Since the comment section can be very deep, we'll limit comments to a breadth of 10.\n",
        "# This may still be a lot more comments than we need for larger discussions.\n",
        "def extract_comments_from_submission(submission_id: str):\n",
        "    try:\n",
        "        submission = reddit.submission(id=submission_id)\n",
        "        submission.comments.replace_more(limit=10)  # Limit to 10 levels of comments\n",
        "        comments = []\n",
        "\n",
        "        for comment in submission.comments.list():\n",
        "            if isinstance(comment, praw.models.MoreComments):\n",
        "                continue\n",
        "\n",
        "            # NOTE: It looks like the top comment may be a user report. We'll ignore if is has certain text.\n",
        "            SKIPTEXT = '**User Report**'\n",
        "            if SKIPTEXT in comment.body:\n",
        "                continue\n",
        "\n",
        "            # Append the comment data to the list\n",
        "            comments.append({\n",
        "                'parent_post_id': submission_id,\n",
        "                'parent_comment_id': comment.parent_id,\n",
        "                'comment_id': comment.id,\n",
        "                'author': str(comment.author),\n",
        "                'created_utc': comment.created_utc,\n",
        "                'score': comment.score,\n",
        "                'body': comment.body\n",
        "            })\n",
        "\n",
        "        return comments\n",
        "\n",
        "    except Exception as e:\n",
        "        # Get the HTTP error code if available\n",
        "        if hasattr(e, 'response') and e.response is not None:\n",
        "            error_code = e.response.status_code\n",
        "            print(f\"HTTP Error {error_code} while fetching comments for submission {submission_id}\")\n",
        "        else:\n",
        "            error_code = None\n",
        "\n",
        "        # Print the an erroor message and return nothing.\n",
        "        print(f\"Error fetching comments for submission {submission_id}: {e}\")\n",
        "        return []\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gYeljFKM8BkV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission ID: 1k0t4jk\n",
            "Title: Nivea Along\n",
            "Number of comments: 6\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>parent_post_id</th>\n",
              "      <th>parent_comment_id</th>\n",
              "      <th>comment_id</th>\n",
              "      <th>author</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>score</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t3_1k0t4jk</td>\n",
              "      <td>mngn956</td>\n",
              "      <td>Alert_Barber_3105</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>6</td>\n",
              "      <td>The skin cream?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t3_1k0t4jk</td>\n",
              "      <td>mngmxdi</td>\n",
              "      <td>chrissurra</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>4</td>\n",
              "      <td>You mean Neveah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t3_1k0t4jk</td>\n",
              "      <td>mngoka2</td>\n",
              "      <td>Reasonable_Roger</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>Psoriasis calls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t1_mngn956</td>\n",
              "      <td>mngnj1n</td>\n",
              "      <td>Own-Foundation3873</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>pow till it creams</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t1_mngmxdi</td>\n",
              "      <td>mngnbpk</td>\n",
              "      <td>Own-Foundation3873</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>yesss sir</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  parent_post_id parent_comment_id comment_id              author  \\\n",
              "0        1k0t4jk        t3_1k0t4jk    mngn956   Alert_Barber_3105   \n",
              "1        1k0t4jk        t3_1k0t4jk    mngmxdi          chrissurra   \n",
              "2        1k0t4jk        t3_1k0t4jk    mngoka2    Reasonable_Roger   \n",
              "3        1k0t4jk        t1_mngn956    mngnj1n  Own-Foundation3873   \n",
              "4        1k0t4jk        t1_mngmxdi    mngnbpk  Own-Foundation3873   \n",
              "\n",
              "    created_utc  score                body  \n",
              "0  1.744832e+09      6     The skin cream?  \n",
              "1  1.744832e+09      4     You mean Neveah  \n",
              "2  1.744832e+09      1     Psoriasis calls  \n",
              "3  1.744832e+09      1  pow till it creams  \n",
              "4  1.744832e+09      1           yesss sir  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Show the results from one submission's comments\n",
        "submission_id = submission_collection.iloc[0]['id']\n",
        "\n",
        "# How many actual comments are there for this submission?\n",
        "submission = reddit.submission(id=submission_id)\n",
        "print(f\"Submission ID: {submission_id}\")\n",
        "print(f\"Title: {submission.title}\")\n",
        "print(f\"Number of comments: {submission.num_comments}\")\n",
        "\n",
        "# Get the comments for the submission\n",
        "results = extract_comments_from_submission(submission_id)\n",
        "\n",
        "# Create a dataframe of the comments\n",
        "comments_df = pd.DataFrame(results)\n",
        "\n",
        "# Display the comments dataframe\n",
        "display(comments_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vB3PNPj-8BkV"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>parent_post_id</th>\n",
              "      <th>parent_comment_id</th>\n",
              "      <th>comment_id</th>\n",
              "      <th>author</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>score</th>\n",
              "      <th>body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t3_1k0t4jk</td>\n",
              "      <td>mngn956</td>\n",
              "      <td>Alert_Barber_3105</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>6</td>\n",
              "      <td>The skin cream?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t3_1k0t4jk</td>\n",
              "      <td>mngmxdi</td>\n",
              "      <td>chrissurra</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>4</td>\n",
              "      <td>You mean Neveah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t3_1k0t4jk</td>\n",
              "      <td>mngoka2</td>\n",
              "      <td>Reasonable_Roger</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>Psoriasis calls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t1_mngn956</td>\n",
              "      <td>mngnj1n</td>\n",
              "      <td>Own-Foundation3873</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>pow till it creams</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1k0t4jk</td>\n",
              "      <td>t1_mngmxdi</td>\n",
              "      <td>mngnbpk</td>\n",
              "      <td>Own-Foundation3873</td>\n",
              "      <td>1.744832e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>yesss sir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151632</th>\n",
              "      <td>1jm85ur</td>\n",
              "      <td>t1_mkehvqw</td>\n",
              "      <td>mkejgzy</td>\n",
              "      <td>CultureForsaken3762</td>\n",
              "      <td>1.743277e+09</td>\n",
              "      <td>2</td>\n",
              "      <td>The Little Book That Beats the Market - Joel G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151633</th>\n",
              "      <td>1jm85ur</td>\n",
              "      <td>t1_mka50c0</td>\n",
              "      <td>mkfszsb</td>\n",
              "      <td>Lemonibluff</td>\n",
              "      <td>1.743292e+09</td>\n",
              "      <td>3</td>\n",
              "      <td>Agreed. The fight is to become the EveryGamble...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151634</th>\n",
              "      <td>1jm85ur</td>\n",
              "      <td>t1_mkejgzy</td>\n",
              "      <td>mkel24x</td>\n",
              "      <td>Stamperdoodle1</td>\n",
              "      <td>1.743277e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>amazing recommendation, thank you so much!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151635</th>\n",
              "      <td>1jm85ur</td>\n",
              "      <td>t1_mkel24x</td>\n",
              "      <td>mkely5t</td>\n",
              "      <td>CultureForsaken3762</td>\n",
              "      <td>1.743278e+09</td>\n",
              "      <td>2</td>\n",
              "      <td>My pleasure.  You arent â€œnot smart enoughâ€.  Y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151636</th>\n",
              "      <td>1jm85ur</td>\n",
              "      <td>t1_mkely5t</td>\n",
              "      <td>mketyvm</td>\n",
              "      <td>Stamperdoodle1</td>\n",
              "      <td>1.743280e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>You're the best, thank you for being awesome.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151637 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       parent_post_id parent_comment_id comment_id               author  \\\n",
              "0             1k0t4jk        t3_1k0t4jk    mngn956    Alert_Barber_3105   \n",
              "1             1k0t4jk        t3_1k0t4jk    mngmxdi           chrissurra   \n",
              "2             1k0t4jk        t3_1k0t4jk    mngoka2     Reasonable_Roger   \n",
              "3             1k0t4jk        t1_mngn956    mngnj1n   Own-Foundation3873   \n",
              "4             1k0t4jk        t1_mngmxdi    mngnbpk   Own-Foundation3873   \n",
              "...               ...               ...        ...                  ...   \n",
              "151632        1jm85ur        t1_mkehvqw    mkejgzy  CultureForsaken3762   \n",
              "151633        1jm85ur        t1_mka50c0    mkfszsb          Lemonibluff   \n",
              "151634        1jm85ur        t1_mkejgzy    mkel24x       Stamperdoodle1   \n",
              "151635        1jm85ur        t1_mkel24x    mkely5t  CultureForsaken3762   \n",
              "151636        1jm85ur        t1_mkely5t    mketyvm       Stamperdoodle1   \n",
              "\n",
              "         created_utc  score                                               body  \n",
              "0       1.744832e+09      6                                    The skin cream?  \n",
              "1       1.744832e+09      4                                    You mean Neveah  \n",
              "2       1.744832e+09      1                                    Psoriasis calls  \n",
              "3       1.744832e+09      1                                 pow till it creams  \n",
              "4       1.744832e+09      1                                          yesss sir  \n",
              "...              ...    ...                                                ...  \n",
              "151632  1.743277e+09      2  The Little Book That Beats the Market - Joel G...  \n",
              "151633  1.743292e+09      3  Agreed. The fight is to become the EveryGamble...  \n",
              "151634  1.743277e+09      1         amazing recommendation, thank you so much!  \n",
              "151635  1.743278e+09      2  My pleasure.  You arent â€œnot smart enoughâ€.  Y...  \n",
              "151636  1.743280e+09      1      You're the best, thank you for being awesome.  \n",
              "\n",
              "[151637 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Collect the comments for all the submissions.\n",
        "all_comments = []\n",
        "for submission in submission_collection['id']:\n",
        "    comments = extract_comments_from_submission(submission)\n",
        "    all_comments.extend(comments)\n",
        "    time.sleep(1)  # Optional delay to avoid rate limits\n",
        "\n",
        "# Create a python dataframe of these comments.\n",
        "comments_df = pd.DataFrame.from_records(all_comments)\n",
        "display(comments_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the collected data to parquet format\n",
        "COMMENT_PARQUET_PATH = './data/wallstreetbets-comment-collection.parquet'\n",
        "\n",
        "# Create a pyarrow schema for the comment data\n",
        "comment_schema = pyarrow.schema([\n",
        "    ('parent_post_id', pyarrow.string()),\n",
        "    ('parent_comment_id', pyarrow.string()),\n",
        "    ('comment_id', pyarrow.string()),\n",
        "    ('author', pyarrow.string()),\n",
        "    ('created_utc', pyarrow.float64()),\n",
        "    ('score', pyarrow.int64()),\n",
        "    ('body', pyarrow.string())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hNVWhQB_8BkW"
      },
      "outputs": [],
      "source": [
        "# Write the comments to parquet file. If it exists, append to it.\n",
        "if not os.path.exists(COMMENT_PARQUET_PATH):\n",
        "    comments_df.to_parquet(COMMENT_PARQUET_PATH, engine='pyarrow', schema=comment_schema)\n",
        "else:\n",
        "    old_parquet = pd.read_parquet(COMMENT_PARQUET_PATH, engine='pyarrow', schema=comment_schema)\n",
        "    new_parquet = pd.concat([old_parquet, comments_df])\n",
        "    new_parquet = new_parquet.drop_duplicates(subset=['parent_post_id','parent_comment_id','author','created_utc'], keep='last').reset_index(drop=True)\n",
        "    new_parquet.to_parquet(COMMENT_PARQUET_PATH, engine='pyarrow', schema=comment_schema)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
