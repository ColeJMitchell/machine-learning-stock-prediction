{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f6387a",
   "metadata": {},
   "source": [
    "# Evaluation of stock prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3b317c",
   "metadata": {},
   "source": [
    "## Part 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3a098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime, time\n",
    "from termcolor import colored\n",
    "\n",
    "from requests import Session\n",
    "from requests_cache import CacheMixin, SQLiteCache\n",
    "from requests_ratelimiter import LimiterMixin, MemoryQueueBucket\n",
    "from pyrate_limiter import Duration, RequestRate, Limiter\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Dependencies for the LSTM model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%pip install --upgrade tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import MeanSquaredError as mse\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, root_mean_squared_error\n",
    "from tensorflow import keras\n",
    "from keras.utils import pad_sequences\n",
    "%pip install gputil\n",
    "import GPUtil as GPU\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ac0bf2",
   "metadata": {},
   "source": [
    "## Part 1: Load the previously trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17f952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./data/stock_prediction.h5\"\n",
    "model = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
    "\n",
    "# Show model details\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e03540e",
   "metadata": {},
   "source": [
    "## Part 2: Create Test Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3a0e8",
   "metadata": {},
   "source": [
    "Here we list some variables for the test stocks. We've downloaded the for one past year from the NASDAQ site. There are some formatting specific things, that we will fix in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a773be",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTDATADIR = \"./data/test_stocks/\"\n",
    "TESTSTOCKS = [\n",
    "    \"AAPL\", # Apple\n",
    "    \"AMD\",  # AMD\n",
    "    \"AMZN\", # Amazon\n",
    "    \"META\", # Meta Platforms\n",
    "    \"NFLX\", # Netflix\n",
    "    \"QCOM\", # Qualcomm\n",
    "    \"SBUX\", # Starbucks\n",
    "    \"SCSO\", # Cisco\n",
    "    \"TSLA\", # Tesla\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceefe930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the test data for each stock\n",
    "test_data = {}\n",
    "for stock in TESTSTOCKS:\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(f\"{TESTDATADIR}{stock}.csv\")\n",
    "    \n",
    "    # The data column is given in the format \"MM/DD/YYYY\", change that to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y')\n",
    "    \n",
    "    # Remove the dollar sign from the columns where the value is monetary\n",
    "    monetary_columns = ['Close/Last', 'Open', 'High', 'Low']\n",
    "    for col in monetary_columns:\n",
    "        df[col] = df[col].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "        \n",
    "    # Drop the columns not in Date and Close/Last\n",
    "    df = df[['Date', 'Close/Last']]\n",
    "    \n",
    "    # Rename the columns to 'Date' and 'Close'\n",
    "    df.columns = ['Date', 'Close']\n",
    "        \n",
    "    # Add the stock to the data dictionary\n",
    "    test_data[stock] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bed7fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the closing prices for each stock and store the scaler and df in a tuple.\n",
    "for stock, df in test_data.items():\n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    # Fit the scaler to the closing prices\n",
    "    df['Close'] = scaler.fit_transform(df['Close'].values.reshape(-1, 1))\n",
    "    \n",
    "    # Store the scaler and df in a tuple\n",
    "    test_data[stock] = (scaler, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b1bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_test and y_test for each stock\n",
    "for stock, (scaler, df) in test_data.items():\n",
    "    # Data is the closing prices\n",
    "    data = df['Close'].values\n",
    "    \n",
    "    # Preprocess the data\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(30, len(data)):\n",
    "        X_test.append(data[i-30:i])\n",
    "        y_test.append(data[i])\n",
    "        \n",
    "    # Turn these data to numpy format, reshape, and return.\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "    \n",
    "    # Save the data as (df, X_test, y_test, scaler)\n",
    "    test_data[stock] = (df, X_test, y_test, scaler)\n",
    "        \n",
    "    # Print final details\n",
    "    print(f\"Final data for the stock '{stock}'...\")\n",
    "    print(f\"   Shape of X_test: {X_test.shape}\")\n",
    "    print(f\"   Shape of y_test: {y_test.shape}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c728c854",
   "metadata": {},
   "source": [
    "## Part 3: Predicting with the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201cda89",
   "metadata": {},
   "source": [
    "### Part 3.1: Make predictions with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eece06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stock_price(model, ticker_data):\n",
    "    \"\"\"\n",
    "    Predicts the stock price using the trained model.\n",
    "    The input data should be a 3D array of shape (n_samples, 30, 1).\n",
    "    The input data should be preprocessed in the same way as the training data. (normalized, reshaped)\n",
    "    \"\"\"\n",
    "    # Get the input test data.\n",
    "    X_test, y_test, scaler = ticker_data\n",
    "    \n",
    "    # Assert the input data shape\n",
    "    expected_shape = (None, 30, 1)\n",
    "    assert len(X_test.shape) == 3, f\"Expected 3D array, got {len(X_test.shape)}D array\"\n",
    "    assert X_test.shape[1] == 30, f\"Expected 30 time steps, got {X_test.shape[1]} time steps\"\n",
    "    assert X_test.shape[2] == 1, f\"Expected 1 feature, got {X_test.shape[2]} features\"\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c60df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that cases are created, as (dataframe, X_test, y_test, scaler) for each ticker, we can predict the stock prices\n",
    "for ticker, (dataframe, X_test, y_test, scaler) in test_data.items():\n",
    "    # Predict the stock price\n",
    "    predictions = predict_stock_price(model, (X_test, y_test, scaler))\n",
    "    \n",
    "    # Inverse transform the predictions and y_test to get the actual prices\n",
    "    predictions_unscaled = scaler.inverse_transform(predictions)\n",
    "    y_test_unscaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    # Create a DataFrame to hold the results\n",
    "    results = pd.DataFrame({\n",
    "        'Date': dataframe['Date'][30:],\n",
    "        'Actual_Scaled': y_test,\n",
    "        'Prediction_Scaled': predictions.flatten(),\n",
    "        'Actual': y_test_unscaled.flatten(),\n",
    "        'Prediction': predictions_unscaled.flatten()\n",
    "    })\n",
    "    \n",
    "    # Update the test_data dictionary with the results\n",
    "    test_data[ticker] = (dataframe, X_test, y_test, scaler, results)\n",
    "    \n",
    "    # Print the first few rows of the results\n",
    "    print(f\"Results for {ticker}:\")\n",
    "    print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dde64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crate a 10 subplot grid to show the results for each stock\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i, (ticker, (dataframe, X_test, y_test, scaler, results)) in enumerate(test_data.items()):\n",
    "    # Add the subplot for each stock\n",
    "    plt.subplot(5, 2, i + 1)\n",
    "    plt.plot(results['Date'], results['Actual'], label='Actual Price', color='blue')\n",
    "    plt.plot(results['Date'], results['Prediction'], label='Predicted Price', color='red')\n",
    "    plt.title(f'{ticker} Stock Price Prediction')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752a234d",
   "metadata": {},
   "source": [
    "### Part 3.2: Use the predective capabilities of the model to simulate trading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae5de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize the trading results into a DataFrame\n",
    "\n",
    "# Define the buy signal logic\n",
    "def buy_shares(cash, actual_price_today):\n",
    "    \"\"\"\n",
    "    Buys as many shares as possible with the available cash.\n",
    "    Returns the updated cash and number of shares bought.\n",
    "    \"\"\"\n",
    "    shares_to_buy = cash // actual_price_today\n",
    "    cash -= shares_to_buy * actual_price_today\n",
    "    return cash, shares_to_buy\n",
    "\n",
    "# Define the sell signal logic\n",
    "def sell_shares(cash, shares, actual_price_today):\n",
    "    \"\"\"\n",
    "    Sells all shares owned.\n",
    "    Returns the updated cash and sets shares to 0.\n",
    "    \"\"\"\n",
    "    cash += shares * actual_price_today\n",
    "    shares = 0\n",
    "    return cash, shares\n",
    "\n",
    "# Simulate paper trading for each stock\n",
    "def simulate_paper_trading(test_data, initial_investment=10000):\n",
    "    \"\"\"\n",
    "    Simulates paper trading for each stock in the test_data dictionary.\n",
    "    Returns a DataFrame with the final portfolio value and yield for each stock.\n",
    "    \"\"\"\n",
    "    trading_results = []\n",
    "\n",
    "    for ticker, (dataframe, X_test, y_test, scaler, results) in test_data.items():\n",
    "        cash = initial_investment\n",
    "        shares = 0\n",
    "        portfolio_value = []\n",
    "\n",
    "        # Iterate through the results DataFrame\n",
    "        for i in range(len(results) - 1):  # Exclude the last day since we can't predict beyond it\n",
    "            actual_price_today = results['Actual'].iloc[i]\n",
    "            predicted_price_tomorrow = results['Prediction'].iloc[i + 1]\n",
    "\n",
    "            # Buy signal: Predicted price tomorrow > Actual price today\n",
    "            if predicted_price_tomorrow > actual_price_today:\n",
    "                cash, shares_bought = buy_shares(cash, actual_price_today)\n",
    "                shares += shares_bought\n",
    "\n",
    "            # Sell signal: Predicted price tomorrow < Actual price today\n",
    "            elif predicted_price_tomorrow < actual_price_today and shares > 0:\n",
    "                cash, shares = sell_shares(cash, shares, actual_price_today)\n",
    "\n",
    "            # Calculate the portfolio value (cash + value of shares)\n",
    "            portfolio_value.append(cash + shares * actual_price_today)\n",
    "\n",
    "        # Final portfolio value\n",
    "        final_portfolio_value = cash + shares * results['Actual'].iloc[-1]\n",
    "        yield_percentage = ((final_portfolio_value - initial_investment) / initial_investment) * 100\n",
    "\n",
    "        # Store the results\n",
    "        trading_results.append({\n",
    "            'Ticker': ticker,\n",
    "            'Final Portfolio Value': final_portfolio_value,\n",
    "            'Yield (%)': yield_percentage\n",
    "        })\n",
    "\n",
    "        # Print results for the stock\n",
    "        print(f\"Results for {ticker}:\")\n",
    "        print(f\"   Final Portfolio Value: ${final_portfolio_value:.2f}\")\n",
    "        print(f\"   Yield: {yield_percentage:.2f}%\")\n",
    "        print()\n",
    "\n",
    "    # Convert trading results to a DataFrame for display\n",
    "    trading_results_df = pd.DataFrame(trading_results)\n",
    "    return trading_results_df\n",
    "\n",
    "# Run the simulation\n",
    "trading_results_df = simulate_paper_trading(test_data, initial_investment=10000)\n",
    "\n",
    "# Display the trading results\n",
    "display(trading_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65894adc",
   "metadata": {},
   "source": [
    "### Part 3.3: Visualize the results of the trading simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c71ec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot these results for each stock with red and green lines for gains and losses\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i, (ticker, (dataframe, X_test, y_test, scaler, results)) in enumerate(test_data.items()):\n",
    "    # Add the subplot for each stock\n",
    "    plt.subplot(5, 2, i + 1)\n",
    "    plt.plot(results['Date'], results['Actual'], label='Actual Price', color='blue')\n",
    "    plt.plot(results['Date'], results['Prediction'], label='Predicted Price', color='red')\n",
    "    \n",
    "    # Highlight gains and losses\n",
    "    gains = results['Actual'] > results['Prediction']\n",
    "    losses = results['Actual'] < results['Prediction']\n",
    "    \n",
    "    plt.fill_between(results['Date'], results['Actual'], where=gains, color='green', alpha=0.3)\n",
    "    plt.fill_between(results['Date'], results['Actual'], where=losses, color='red', alpha=0.3)\n",
    "    \n",
    "    plt.title(f'{ticker} Stock Price Prediction')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a0d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a header\n",
    "print(\"\\n{:<8} {:<22} {:<10}\".format('Ticker', 'Final Portfolio Value', 'Yield (%)'))\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Iterate through the test data and print colored results\n",
    "for ticker, (dataframe, X_test, y_test, scaler, results) in test_data.items():\n",
    "    final_value = trading_results_df.loc[trading_results_df['Ticker'] == ticker, 'Final Portfolio Value'].values[0]\n",
    "    yield_pct = trading_results_df.loc[trading_results_df['Ticker'] == ticker, 'Yield (%)'].values[0]\n",
    "    \n",
    "    # Format the values\n",
    "    final_value_str = \"${:.2f}\".format(final_value)\n",
    "    yield_str = \"{:.2f}%\".format(yield_pct)\n",
    "    \n",
    "    # Color based on yield (green for positive, red for negative)\n",
    "    if yield_pct >= 0:\n",
    "        colored_yield = colored(yield_str, 'green')\n",
    "    else:\n",
    "        colored_yield = colored(yield_str, 'red')\n",
    "    \n",
    "    # Print the row\n",
    "    print(\"{:<8} {:<22} {}\".format(ticker, final_value_str, colored_yield))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d876d26",
   "metadata": {},
   "source": [
    "### Part 3.4: Store the results of the simulated trading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Create a dataframe from the results.\n",
    "dataframe_columns = ['Ticker', 'Actual', 'Prediction', 'Date']\n",
    "trading_results_df = pd.DataFrame(columns=dataframe_columns)\n",
    "for ticker, (dataframe, X_test, y_test, scaler, results) in test_data.items():\n",
    "    # Create a DataFrame for the results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Ticker': ticker,\n",
    "        'Actual': results['Actual_Scaled'],\n",
    "        'Prediction': results['Prediction_Scaled'],\n",
    "        'Date': results['Date']\n",
    "    })\n",
    "    \n",
    "    # Append to the main DataFrame\n",
    "    trading_results_df = pd.concat([trading_results_df, results_df], ignore_index=True)\n",
    "    \n",
    "# Display the trading results DataFrame\n",
    "display(trading_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ddde18",
   "metadata": {},
   "source": [
    "### Part 3.5: Explote the accuracy of the model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a635ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the accuracy for a stock in a given week with the results DataFrame\n",
    "def calculate_weekly_accuracy(results, week: int, year: int):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of predictions for a given week.\n",
    "    \"\"\"\n",
    "    # Convert the 'Date' column to datetime format\n",
    "    results['Date'] = pd.to_datetime(results['Date'])\n",
    "    \n",
    "    # Filter the results for the given week and year\n",
    "    week_start = pd.to_datetime(f'{year}-W{week}-1', format='%Y-W%W-%w')\n",
    "    week_end = week_start + pd.DateOffset(days=6)\n",
    "    weekly_results = results[(results['Date'] >= week_start) & (results['Date'] <= week_end)]\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    correct_predictions = ((weekly_results['Actual'] - weekly_results['Prediction']).abs() < 0.05 * weekly_results['Actual']).sum()\n",
    "    total_predictions = len(weekly_results)\n",
    "    \n",
    "    if total_predictions == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf88113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the weekly accuracy for each stock, using a colored table\n",
    "for ticker, (dataframe, X_test, y_test, scaler, results) in test_data.items():\n",
    "    # Calculate the weekly accuracy for the current year\n",
    "    current_year = datetime.datetime.now().year\n",
    "    weekly_accuracy = []\n",
    "    \n",
    "    for week in range(1, 10):\n",
    "        accuracy = calculate_weekly_accuracy(results, week, current_year)\n",
    "        weekly_accuracy.append(accuracy)\n",
    "    \n",
    "    # Create a DataFrame to hold the weekly accuracy\n",
    "    weekly_accuracy_df = pd.DataFrame({\n",
    "        'Week': range(1, 10),\n",
    "        'Accuracy': weekly_accuracy\n",
    "    })\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Weekly Accuracy for {ticker}:\")\n",
    "    \n",
    "    # Print colored results\n",
    "    for index, row in weekly_accuracy_df.iterrows():\n",
    "        week_str = f\"Week {row['Week']}\"\n",
    "        accuracy_str = \"{:.2f}%\".format(row['Accuracy'] * 100)\n",
    "        \n",
    "        # Color based on accuracy (green for high accuracy, red for low accuracy)\n",
    "        if row['Accuracy'] >= 0.8:\n",
    "            colored_accuracy = colored(accuracy_str, 'green')\n",
    "        elif row['Accuracy'] >= 0.5:\n",
    "            colored_accuracy = colored(accuracy_str, 'yellow')\n",
    "        else:\n",
    "            colored_accuracy = colored(accuracy_str, 'red')\n",
    "        \n",
    "        # Print the row\n",
    "        print(f\"{week_str}: {colored_accuracy}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1cf137",
   "metadata": {},
   "source": [
    "## Part 4: Create prediction evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36991ea5",
   "metadata": {},
   "source": [
    "### Part 4.1: Evaluate and store some metrics for the model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec23b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame to hold the evaluation metrics\n",
    "evaluation_metrics = pd.DataFrame(columns=['Ticker', 'MSE', 'RMSE', 'MAE', 'R2'])\n",
    "\n",
    "# Providide the MSE< RMSE, MAE, and R2 for each stock (Note small sample size and specificity of the data)\n",
    "for ticker, (dataframe, X_test, y_test, scaler, results) in test_data.items():\n",
    "    # Calculate the Mean Squared Error (MSE)\n",
    "    mse_value = mean_squared_error(y_test, results['Prediction_Scaled'].values)\n",
    "    \n",
    "    # Calculate the Root Mean Squared Error (RMSE)\n",
    "    rmse_value = np.sqrt(mse_value)\n",
    "    \n",
    "    # Calculate the Mean Absolute Error (MAE)\n",
    "    mae_value = mean_absolute_error(y_test, results['Prediction_Scaled'].values)\n",
    "    \n",
    "    # Calculate the R-squared value\n",
    "    r2_value = r2_score(y_test, results['Prediction_Scaled'].values)\n",
    "    \n",
    "    # Store the metrics in the DataFrame\n",
    "    evaluation_metrics_row = pd.DataFrame({\n",
    "        'Ticker': [ticker],\n",
    "        'MSE': [mse_value],\n",
    "        'RMSE': [rmse_value],\n",
    "        'MAE': [mae_value],\n",
    "        'R2': [r2_value]\n",
    "    })\n",
    "    evaluation_metrics = pd.concat([evaluation_metrics, evaluation_metrics_row], ignore_index=True)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Results for {ticker}:\")\n",
    "    print(f\"   MSE: {mse_value:.4f}\")\n",
    "    print(f\"   RMSE: {rmse_value:.4f}\")\n",
    "    print(f\"   MAE: {mae_value:.4f}\")\n",
    "    print(f\"   R-squared: {r2_value:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ac819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the evaluation metrics\n",
    "display(evaluation_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beab729",
   "metadata": {},
   "source": [
    "### Part 4.2: Create Evaluation metrics per weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2f5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weeek_of_dataframe(df, ticker, start_date, end_date):\n",
    "    \n",
    "    # Slice the data for the specific ticker.\n",
    "    df = df[df['Ticker'] == ticker]\n",
    "    \n",
    "    # Slice the data for the specific date range.\n",
    "    df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "\n",
    "    # return a copy of the dataframe\n",
    "    return df.copy()\n",
    "\n",
    "\n",
    "# Calculate the weekly metric for each stock\n",
    "def calculate_weekly_metric(data, start_date='2025-01-01', weeks=10):\n",
    "    weekly_metrics = pd.DataFrame(columns=['Ticker', 'Week', 'Metric', 'Value'])\n",
    "\n",
    "    for ticker in data['Ticker'].unique():\n",
    "        # Slice the partial data for the specific ticker.\n",
    "        current_data = data[data['Ticker'] == ticker]\n",
    "        \n",
    "        # Slice the data for each date range.\n",
    "        for week in range(1, weeks):\n",
    "            # Get the data for the specific week\n",
    "            begin_date = datetime.datetime.strptime(start_date, '%Y-%m-%d') + datetime.timedelta(weeks=week-1)\n",
    "            end_date = begin_date + datetime.timedelta(weeks=1)\n",
    "            \n",
    "            # Filter the data for the specific week\n",
    "            results_filtered = get_weeek_of_dataframe(current_data, \n",
    "                                                      ticker, \n",
    "                                                      start_date=start_date,\n",
    "                                                      end_date=end_date)\n",
    "            \n",
    "            # Check if the filtered DataFrame is empty\n",
    "            if results_filtered.empty:\n",
    "                print(f\"No data available for {ticker} from {start_date} to {end_date}.\")\n",
    "                continue\n",
    "            \n",
    "            # Calculate the metrics for the week.\n",
    "            actual_prices = results_filtered['Actual'].values\n",
    "            predicted_prices = results_filtered['Prediction'].values\n",
    "\n",
    "            # Calculate each metric\n",
    "            mse_value = mean_squared_error(actual_prices, predicted_prices)\n",
    "            rmse_value = np.sqrt(mse_value)\n",
    "            mae_value = mean_absolute_error(actual_prices, predicted_prices)\n",
    "            r2_value = r2_score(actual_prices, predicted_prices)\n",
    "            \n",
    "            # Create a DataFrame for the metrics\n",
    "            metrics_df = pd.DataFrame({\n",
    "                'Ticker': [ticker] * 4,\n",
    "                'Week': [week] * 4,\n",
    "                'Metric': ['MSE', 'RMSE', 'MAE', 'R2'],\n",
    "                'Value': [mse_value, rmse_value, mae_value, r2_value]\n",
    "            })\n",
    "            \n",
    "            # Append the metrics DataFrame to the weekly_metrics DataFrame\n",
    "            weekly_metrics = pd.concat([weekly_metrics, metrics_df], ignore_index=True)\n",
    "            \n",
    "    # Return the weekly metrics DataFrame\n",
    "    return weekly_metrics\n",
    "\n",
    "# Calculate the weekly metrics for each stock\n",
    "weekly_metrics = calculate_weekly_metric(trading_results_df)\n",
    "\n",
    "# Pivot the DataFrame to have metrics as columns\n",
    "weekly_metrics_pivot = weekly_metrics.pivot_table(index=['Ticker', 'Week'], columns='Metric', values='Value').reset_index()\n",
    "\n",
    "# Display the weekly metrics DataFrame\n",
    "display(weekly_metrics_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d18408",
   "metadata": {},
   "source": [
    "## Part 5: Plot and explore the evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceef9b5",
   "metadata": {},
   "source": [
    "### Part 5.1: Show the metrics per weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e61942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the weekly metrics for each stock, where the stocks are superimposed on each other\n",
    "plt.figure(figsize=(20, 10))\n",
    "for metric in ['MSE', 'RMSE', 'MAE', 'R2']:\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for ticker in weekly_metrics_pivot['Ticker'].unique():\n",
    "        # Filter the data for the specific ticker\n",
    "        ticker_data = weekly_metrics_pivot[weekly_metrics_pivot['Ticker'] == ticker]\n",
    "        \n",
    "        # Plot the metric\n",
    "        plt.plot(ticker_data['Week'], ticker_data[metric], label=ticker)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.title(f'Weekly {metric} for Each Stock')\n",
    "    plt.xlabel('Week')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf925d86",
   "metadata": {},
   "source": [
    "### Part 5.2: Reframe the data tables and calculate metrics cumulatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86793bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weekly metrics per all stocks\n",
    "weekly_metrics_all = pd.DataFrame(columns=['Week', 'Metric', 'Value'])\n",
    "weeks = 10\n",
    "\n",
    "# Add wee label date...\n",
    "def get_week_label(date):\n",
    "    # Get the week after the start date.\n",
    "    start_date = datetime.datetime.strptime('2025-01-01', '%Y-%m-%d')\n",
    "    week = ((date - start_date).days // 7)+ 1\n",
    "    return week\n",
    "\n",
    "# Add the week label to the dataframe\n",
    "trading_results_df['Week'] = trading_results_df['Date'].apply(get_week_label)\n",
    "\n",
    "# Note: Some weeks are negative since the start date is prior to the first date.\n",
    "\n",
    "# Display the updated dataframe\n",
    "display(trading_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0332f05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate weekly metrics across all stocks\n",
    "def calculate_weekly_metric_all(data):\n",
    "    weeks = [week for week in data['Week'].unique() if week > 0]\n",
    "    weekly_metrics = pd.DataFrame(columns=['Week', 'Metric', 'Value'])\n",
    "    max_weeks = max(weeks)\n",
    "\n",
    "    for week in range(1, max_weeks + 1):\n",
    "        # Get the data for the specific week\n",
    "        results_filtered = data[data['Week'] == week]\n",
    "        \n",
    "        # Check if the filtered DataFrame is empty\n",
    "        if results_filtered.empty:\n",
    "            print(f\"No data available for week {week}.\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate the metrics for the week.\n",
    "        actual_prices = results_filtered['Actual'].values\n",
    "        predicted_prices = results_filtered['Prediction'].values\n",
    "\n",
    "        # Calculate each metric\n",
    "        mse_value = mean_squared_error(actual_prices, predicted_prices)\n",
    "        rmse_value = np.sqrt(mse_value)\n",
    "        mae_value = mean_absolute_error(actual_prices, predicted_prices)\n",
    "        r2_value = r2_score(actual_prices, predicted_prices)\n",
    "        \n",
    "        # Create a DataFrame for the metrics\n",
    "        metrics_df = pd.DataFrame({\n",
    "            'Week': [week] * 4,\n",
    "            'Metric': ['MSE', 'RMSE', 'MAE', 'R2'],\n",
    "            'Value': [mse_value, rmse_value, mae_value, r2_value]\n",
    "        })\n",
    "        \n",
    "        # Append the metrics DataFrame to the weekly_metrics DataFrame\n",
    "        weekly_metrics = pd.concat([weekly_metrics, metrics_df], ignore_index=True)\n",
    "            \n",
    "    # Return the weekly metrics DataFrame\n",
    "    return weekly_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b1772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the weekly metric for all stocks\n",
    "weekly_metrics_all = calculate_weekly_metric_all(trading_results_df)\n",
    "\n",
    "# Pivot the DataFrame to have metrics as columns\n",
    "weekly_metrics_all_pivot = weekly_metrics_all.pivot_table(index='Week', columns='Metric', values='Value').reset_index()\n",
    "\n",
    "# Display the weekly metrics DataFrame\n",
    "display(weekly_metrics_all_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a9a8f",
   "metadata": {},
   "source": [
    "### Part 5.3: View the cumulative metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d61380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the weekly metrics for each metric\n",
    "plt.figure(figsize=(20, 10))\n",
    "for metric in ['MSE', 'RMSE', 'MAE', 'R2']:\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.plot(weekly_metrics_all_pivot['Week'], weekly_metrics_all_pivot[metric], label=metric)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.title(f'Weekly {metric} for All Stocks')\n",
    "    plt.xlabel('Week')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
